{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b31e21-a0f9-46b1-896f-ad5fb83cf807",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b027f58-0bcf-4e69-afb8-a538753b88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import string\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d974f0-1885-437d-b0fb-adf7d95484b6",
   "metadata": {},
   "source": [
    "# Raw Reviews\n",
    "\n",
    "## Load data\n",
    "\n",
    "Like in Exercise 1, read all the training data, including the reviews and the scores associated to each one. You can use the following helper functions to read the data:\n",
    "\n",
    "1. Be sure to have downloaded the dataset from the link provided in the exercise and have read the README file\n",
    "1. Be sure to have copied the dataset next to this Jupyter (.ipynb file)\n",
    "1. Be sure to have installed:\n",
    "    * Pytorch\n",
    "    * NLTK (This library is going to be used only for the stemming process, no more)\n",
    "    * Sklearn (Only for building a Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efb3393-4a19-40bf-9e5c-557bd1331da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(item):\n",
    "    \"\"\" Function tha gets only the first number of the name of the file and organizes the files base on that\"\"\"\n",
    "    \n",
    "    return int(os.path.basename(item).split('_')[0])\n",
    "\n",
    "def read_raw_text(path_data):\n",
    "    \"\"\" Function for reading the raw data in the .txt files. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_data: str\n",
    "        path of the folder that contains the data that is going to be used. (should be test or train)\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    data,scores: array_like\n",
    "        Data arrays, X is an array of shape [#documents of the dataset, #words in the vocabulary], y is an array of shape [#documents,] \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    scores = []\n",
    "    \n",
    "    sentiments = ['pos', 'neg']\n",
    "    for sentiment in sentiments:\n",
    "        path_vocab_pos = os.path.join(\"../datasets\", \"aclImdb\", path_data, sentiment, \"*.txt\")\n",
    "        \n",
    "        for filename in sorted(glob.glob(path_vocab_pos), key=sorter):\n",
    "            \n",
    "            with open(filename) as f:\n",
    "                \n",
    "                lines = f.read()\n",
    "                \n",
    "                data.append(lines)\n",
    "                scores.append(int(os.path.basename(filename).split('_')[1].strip('.txt')))\n",
    "    return data, scores\n",
    "\n",
    "\n",
    "def read_vocab():\n",
    "    \"\"\" Function for reading the vocabulary (.vocab file). \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    vocab: list\n",
    "        list with the values different tokens that compose the vocabulary ...... \n",
    "    \"\"\"\n",
    "    \n",
    "    path_vocab = os.path.join(\"..\", \"datasets\", \"aclImdb\", \"imdb.vocab\")\n",
    "    \n",
    "    with open(path_vocab, encoding='utf-8') as f:\n",
    "        lines = f.read()\n",
    "\n",
    "    lines = lines.split('\\n')\n",
    "    \n",
    "    vocab = []\n",
    "    for line in lines:\n",
    "        vocab.append(line)\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d859674d-6750-4159-a5d0-10238bcce7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the vocabulary\n",
    "vocabulary = read_vocab()\n",
    "# Read reviews and y\n",
    "data, scores = read_raw_text('train')\n",
    "data_test, scores_test = read_raw_text('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab2f64-ad0c-4696-8449-c6ad584b554f",
   "metadata": {},
   "source": [
    "## Task 1: Pipeline for Cleaning the Raw Reviews \n",
    "\n",
    "> **Hint**: You can use the functions you have already implemented in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8fe7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    def __init__(self):\n",
    "        self.steps = []\n",
    "\n",
    "    def add_step(self, step, input_column = None, output_column = None, active=True):\n",
    "        self.steps.append({'step': step, 'input': input_column, 'output': output_column, 'active': active})\n",
    "\n",
    "    def process(self, df):\n",
    "        df_copy = df.copy()\n",
    "        for step in self.steps:\n",
    "            if step['active']:\n",
    "                if step['input'] and step['output']:\n",
    "                    df_copy[step['output']] = df_copy[step['input']].apply(step['step'])\n",
    "                else:\n",
    "                    df_copy = step['step'](df_copy)\n",
    "        return df_copy\n",
    "\n",
    "    def set_active(self, step_name, active):\n",
    "        for step in self.steps:\n",
    "            if step['step'].__name__ == step_name:\n",
    "                step['active'] = active\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2885293",
   "metadata": {},
   "source": [
    "### Tokenising the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "050c02d1-61be-4c6e-8600-7b8bfdaf36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise TypeError(\"Input must be a string.\")\n",
    "    if not text:\n",
    "        return []\n",
    "    # Split on any whitespace or punctuation character\n",
    "    tokens = re.split(r'[\\s{}]+'.format(re.escape(string.punctuation)), text.lower())\n",
    "    # Remove empty tokens\n",
    "    tokens = [token for token in tokens if token]\n",
    "    return tokens\n",
    "\n",
    "def load_data_to_df(data, scores):\n",
    "    df = pd.DataFrame(data={'text': data, 'score': scores})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "883ea311",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data_to_df(data, scores)\n",
    "test_df = load_data_to_df(data_test, scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "233140bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def filter_high_frequency_terms(df, column, max_freq=0.2):\n",
    "    n_docs = len(df)\n",
    "    \n",
    "    # document frequency\n",
    "    doc_freq = Counter(chain.from_iterable(set(toks) for toks in df[column]))\n",
    "    cutoff = max_freq * n_docs\n",
    "    \n",
    "    drop_tokens = {tok for tok, dfreq in doc_freq.items() if dfreq > cutoff}\n",
    "\n",
    "    df['filtered_tokens'] = df[column].apply(lambda x: [tok for tok in x if tok not in drop_tokens])\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b197cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numbers(tokens):\n",
    "    if not isinstance(tokens, list):\n",
    "        raise TypeError(\"Input must be a list of tokens.\")\n",
    "    return [re.sub(r'\\d+', '<NUM>', token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd92653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame after preprocessing:\n",
      "                                                text  score  \\\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      9   \n",
      "1  If you like adult comedy cartoons, like South ...      7   \n",
      "2  Bromwell High is nothing short of brilliant. E...      9   \n",
      "3  \"All the world's a stage and its people actors...     10   \n",
      "4  FUTZ is the only show preserved from the exper...      8   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [bromwell, high, is, a, cartoon, comedy, it, r...   \n",
      "1  [if, you, like, adult, comedy, cartoons, like,...   \n",
      "2  [bromwell, high, is, nothing, short, of, brill...   \n",
      "3  [all, the, world, s, a, stage, and, its, peopl...   \n",
      "4  [futz, is, the, only, show, preserved, from, t...   \n",
      "\n",
      "                                     filtered_tokens  label  new_label  \n",
      "0  [bromwell, high, cartoon, comedy, ran, same, p...      1          3  \n",
      "1  [adult, comedy, cartoons, south, park, nearly,...      1          2  \n",
      "2  [bromwell, high, nothing, short, brilliant, ex...      1          3  \n",
      "3  [world, stage, actors, something, hell, said, ...      1          3  \n",
      "4  [futz, show, preserved, experimental, theatre,...      1          2  \n",
      "Test DataFrame after preprocessing:\n",
      "                                                text  score  label  new_label  \\\n",
      "0  I went and saw this movie last night after bei...     10      1          3   \n",
      "1  My boyfriend and I went to watch The Guardian....     10      1          3   \n",
      "2  My yardstick for measuring a movie's watch-abi...      7      1          2   \n",
      "3  How many movies are there that you can think o...      7      1          2   \n",
      "4  This movie was sadly under-promoted but proved...     10      1          3   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [i, went, and, saw, this, movie, last, night, ...   \n",
      "1  [my, boyfriend, and, i, went, to, watch, the, ...   \n",
      "2  [my, yardstick, for, measuring, a, movie, s, w...   \n",
      "3  [how, many, movies, are, there, that, you, can...   \n",
      "4  [this, movie, was, sadly, under, promoted, but...   \n",
      "\n",
      "                                     filtered_tokens  \n",
      "0  [went, saw, last, night, coaxed, few, friends,...  \n",
      "1  [boyfriend, went, guardian, didn, want, loved,...  \n",
      "2  [yardstick, measuring, ability, squirmy, start...  \n",
      "3  [count, sure, seemed, makers, trying, give, hi...  \n",
      "4  [sadly, under, promoted, proved, truly, except...  \n"
     ]
    }
   ],
   "source": [
    "import test\n",
    "\n",
    "\n",
    "pipeline = PreprocessingPipeline()\n",
    "\n",
    "pipeline.add_step(tokenize, input_column='text', output_column='tokens')\n",
    "pipeline.add_step(replace_numbers, input_column='tokens', output_column='tokens')\n",
    "pipeline.add_step(lambda df: filter_high_frequency_terms(df, 'tokens', max_freq=0.2))\n",
    "\n",
    "# Apply the preprocessing pipeline to the training and test dataframes\n",
    "train_df = pipeline.process(train_df)\n",
    "print(\"Training DataFrame after preprocessing:\")\n",
    "print(train_df.head())\n",
    "\n",
    "test_df = pipeline.process(test_df)\n",
    "print(\"Test DataFrame after preprocessing:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fdfb55d455981",
   "metadata": {},
   "source": [
    "## Task 2: Representations of Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034add3-dae4-4ff6-b11e-c4471349712b",
   "metadata": {},
   "source": [
    "### BOW\n",
    "Each review is represented by a vector. It has the length of the vocabulary and for each word in the review, the vector contains the number of appearances on the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c9b7f5e-9216-4057-b458-04fae00ee909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "def build_bow_csr(df, vocab):\n",
    "    \"\"\"\n",
    "    Build a bag-of-words CSR matrix from a dataframe with a 'filtered_tokens' column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing a 'filtered_tokens' column (list of tokens per document).\n",
    "    vocab : list\n",
    "        List of vocabulary tokens.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bow_csr : scipy.sparse.csr_matrix\n",
    "        Bag-of-words matrix (documents x vocabulary).\n",
    "    \"\"\"\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    rows, cols, data = [], [], []\n",
    "    docs = df['filtered_tokens'].tolist()\n",
    "    for row, doc in enumerate(docs):\n",
    "        ctr = Counter(tok for tok in doc if tok in word2idx)\n",
    "        rows.extend([row] * len(ctr))\n",
    "        cols.extend([word2idx[tok] for tok in ctr])\n",
    "        data.extend(ctr.values())\n",
    "    bow_csr = csr_matrix(\n",
    "        (data, (rows, cols)),\n",
    "        shape=(len(docs), len(vocab)),\n",
    "        dtype=np.int32\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return bow_csr\n",
    "\n",
    "bow_csr_train = build_bow_csr(train_df, vocabulary)\n",
    "bow_csr_test = build_bow_csr(test_df, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c5fca74-2d7b-4b36-88d0-452413549633",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['score'].apply(lambda x: 1 if x > 5 else 0)\n",
    "test_df['label'] = test_df['score'].apply(lambda x: 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ab0e2-2d44-4799-b643-eaab9db26a58",
   "metadata": {},
   "source": [
    "## Task 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "818003cf-55af-4ea6-9ccf-106ed0335752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e72d55ee-dee1-4beb-b710-ef674506861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model ---- is everything ready?\n",
    "# Please refer to this link to the basics of bulding a model with Pytorch \n",
    "#        - https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fbd0f79-4fd5-4176-91cf-e5bc6a086556",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the input dimension input_d, output dimension output_d, batch size, number of epochs, iterations, etc..\n",
    "\n",
    "input_d = bow_csr_train.shape[1]\n",
    "output_d = 1\n",
    "batch_size = 64\n",
    "num_epochs = 30\n",
    "learning_rate = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dfb97223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_to_torch_sparse(csr, *, dtype=torch.float32, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    csr : scipy.sparse.csr_matrix\n",
    "    returns: torch.sparse_coo_tensor with the same shape and data\n",
    "    \"\"\"\n",
    "    # COO gives explicit row/col indices\n",
    "    coo = csr.tocoo()\n",
    "    indices = torch.tensor(\n",
    "        [coo.row, coo.col],   # shape 2 Ã— nnz\n",
    "        dtype=torch.int64,\n",
    "        device=device\n",
    "    )\n",
    "    values  = torch.tensor(\n",
    "        coo.data,\n",
    "        dtype=dtype,\n",
    "        device=device\n",
    "    )\n",
    "    shape = coo.shape\n",
    "    return torch.sparse_coo_tensor(indices, values, shape, dtype=dtype, device=device).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c1370e0-e4b5-4bbe-bc9d-a7130f6aed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LR model\n",
    "model = LogisticRegression(input_d).to(device)\n",
    "\n",
    "# Loss class\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Instantiate the Optimizer Class.Do not forget to set the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the labels\n",
    "train_labels = train_df['label'].values\n",
    "test_labels = test_df['label'].values\n",
    "\n",
    "# Convert the data to torch tensors\n",
    "train_data = csr_to_torch_sparse(bow_csr_train, device=device)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.int8, device=device)\n",
    "test_data = csr_to_torch_sparse(bow_csr_test, device=device)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.int8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a895670-7c60-459e-9bc5-55bf459e76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.6933\n",
      "Epoch [2/30], Loss: 0.6927\n",
      "Epoch [3/30], Loss: 0.6922\n",
      "Epoch [4/30], Loss: 0.6916\n",
      "Epoch [5/30], Loss: 0.6911\n",
      "Epoch [6/30], Loss: 0.6905\n",
      "Epoch [7/30], Loss: 0.6900\n",
      "Epoch [8/30], Loss: 0.6894\n",
      "Epoch [9/30], Loss: 0.6889\n",
      "Epoch [10/30], Loss: 0.6883\n",
      "Epoch [11/30], Loss: 0.6878\n",
      "Epoch [12/30], Loss: 0.6872\n",
      "Epoch [13/30], Loss: 0.6867\n",
      "Epoch [14/30], Loss: 0.6862\n",
      "Epoch [15/30], Loss: 0.6856\n",
      "Epoch [16/30], Loss: 0.6851\n",
      "Epoch [17/30], Loss: 0.6846\n",
      "Epoch [18/30], Loss: 0.6840\n",
      "Epoch [19/30], Loss: 0.6835\n",
      "Epoch [20/30], Loss: 0.6830\n",
      "Epoch [21/30], Loss: 0.6824\n",
      "Epoch [22/30], Loss: 0.6819\n",
      "Epoch [23/30], Loss: 0.6814\n",
      "Epoch [24/30], Loss: 0.6809\n",
      "Epoch [25/30], Loss: 0.6804\n",
      "Epoch [26/30], Loss: 0.6798\n",
      "Epoch [27/30], Loss: 0.6793\n",
      "Epoch [28/30], Loss: 0.6788\n",
      "Epoch [29/30], Loss: 0.6783\n",
      "Epoch [30/30], Loss: 0.6778\n"
     ]
    }
   ],
   "source": [
    "# Define the training loop \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_data)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, train_labels.float())\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a9270e60-2999-400a-ab36-d6cab6ffd094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6782, Test Accuracy: 0.7665\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_data)\n",
    "    test_loss = criterion(test_outputs, test_labels.float())\n",
    "    predicted = torch.round(torch.sigmoid(test_outputs))\n",
    "    accuracy = (predicted == test_labels).float().mean()\n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5188313684cf6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with 4 different sentiments\n",
    "class LogisticRegression4(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression4, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1bb50068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_label'] = train_df['score'].apply(lambda x: 0 if 0 < x < 3 else (1 if 2 < x < 5 else (2 if 6 < x < 9  else 3)))\n",
    "test_df['new_label'] = test_df['score'].apply(lambda x: 0 if 0 < x < 3 else (1 if 2 < x < 5 else (2 if 6 < x < 9  else 3)))\n",
    "train_labels = train_df['new_label'].values\n",
    "test_labels = test_df['new_label'].values\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.int8, device=device)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.int8, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab88b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LR model\n",
    "input_d = bow_csr_train.shape[1]\n",
    "model = LogisticRegression4(input_d).to(device)\n",
    "\n",
    "# Loss class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate the Optimizer Class.Do not forget to set the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "354fabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.3866\n",
      "Epoch [2/30], Loss: 1.3855\n",
      "Epoch [3/30], Loss: 1.3845\n",
      "Epoch [4/30], Loss: 1.3835\n",
      "Epoch [5/30], Loss: 1.3825\n",
      "Epoch [6/30], Loss: 1.3815\n",
      "Epoch [7/30], Loss: 1.3805\n",
      "Epoch [8/30], Loss: 1.3795\n",
      "Epoch [9/30], Loss: 1.3786\n",
      "Epoch [10/30], Loss: 1.3776\n",
      "Epoch [11/30], Loss: 1.3767\n",
      "Epoch [12/30], Loss: 1.3757\n",
      "Epoch [13/30], Loss: 1.3748\n",
      "Epoch [14/30], Loss: 1.3739\n",
      "Epoch [15/30], Loss: 1.3729\n",
      "Epoch [16/30], Loss: 1.3720\n",
      "Epoch [17/30], Loss: 1.3711\n",
      "Epoch [18/30], Loss: 1.3702\n",
      "Epoch [19/30], Loss: 1.3693\n",
      "Epoch [20/30], Loss: 1.3684\n",
      "Epoch [21/30], Loss: 1.3675\n",
      "Epoch [22/30], Loss: 1.3667\n",
      "Epoch [23/30], Loss: 1.3658\n",
      "Epoch [24/30], Loss: 1.3649\n",
      "Epoch [25/30], Loss: 1.3641\n",
      "Epoch [26/30], Loss: 1.3632\n",
      "Epoch [27/30], Loss: 1.3624\n",
      "Epoch [28/30], Loss: 1.3615\n",
      "Epoch [29/30], Loss: 1.3607\n",
      "Epoch [30/30], Loss: 1.3598\n",
      "Test Loss: 1.3606, Test Accuracy: 0.4607\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_data)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, train_labels.long())\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_data)\n",
    "    test_loss = criterion(test_outputs, test_labels.long())\n",
    "    predicted = torch.argmax(test_outputs, dim=1)\n",
    "    accuracy = (predicted == test_labels).float().mean()\n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f6a8a-cf55-4656-bd0a-0e23d839f1ae",
   "metadata": {},
   "source": [
    "# Feed forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79e88629-64a8-43c9-915c-3f29195ab215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedForwardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 64)  # Example hidden layer size\n",
    "        self.fc3 = nn.Linear(64, output_dim)  # For binary classification\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e176e72a-e60e-43c0-94a2-cab4175e3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = bow_csr_train.shape[1]\n",
    "hidden_dimension = 128  # Example size for hidden layer\n",
    "output_dimension = 1    # Binary classification\n",
    "model = FeedForwardModel(input_dimension, hidden_dimension, output_dimension).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # Example for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fcfd981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = csr_to_torch_sparse(bow_csr_train, device=device)\n",
    "train_labels = torch.tensor(train_df['label'].values, dtype=torch.float32, device=device)\n",
    "test_data = csr_to_torch_sparse(bow_csr_test, device=device)\n",
    "test_labels = torch.tensor(test_df['label'].values, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "052fbe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5000, F1 Score: 0.0000\n",
      "Epoch [1/30], Loss: 0.6937\n",
      "Train Accuracy: 0.6050, F1 Score: 0.3602\n",
      "Epoch [2/30], Loss: 0.6827\n",
      "Train Accuracy: 0.7800, F1 Score: 0.7329\n",
      "Epoch [3/30], Loss: 0.6637\n",
      "Train Accuracy: 0.8261, F1 Score: 0.7974\n",
      "Epoch [4/30], Loss: 0.6422\n",
      "Train Accuracy: 0.8647, F1 Score: 0.8504\n",
      "Epoch [5/30], Loss: 0.6183\n",
      "Train Accuracy: 0.8960, F1 Score: 0.8909\n",
      "Epoch [6/30], Loss: 0.5915\n",
      "Train Accuracy: 0.9092, F1 Score: 0.9071\n",
      "Epoch [7/30], Loss: 0.5628\n",
      "Train Accuracy: 0.9168, F1 Score: 0.9156\n",
      "Epoch [8/30], Loss: 0.5319\n",
      "Train Accuracy: 0.9226, F1 Score: 0.9213\n",
      "Epoch [9/30], Loss: 0.4993\n",
      "Train Accuracy: 0.9264, F1 Score: 0.9250\n",
      "Epoch [10/30], Loss: 0.4664\n",
      "Train Accuracy: 0.9310, F1 Score: 0.9296\n",
      "Epoch [11/30], Loss: 0.4331\n",
      "Train Accuracy: 0.9353, F1 Score: 0.9343\n",
      "Epoch [12/30], Loss: 0.3997\n",
      "Train Accuracy: 0.9392, F1 Score: 0.9386\n",
      "Epoch [13/30], Loss: 0.3671\n",
      "Train Accuracy: 0.9433, F1 Score: 0.9429\n",
      "Epoch [14/30], Loss: 0.3360\n",
      "Train Accuracy: 0.9471, F1 Score: 0.9468\n",
      "Epoch [15/30], Loss: 0.3065\n",
      "Train Accuracy: 0.9500, F1 Score: 0.9497\n",
      "Epoch [16/30], Loss: 0.2787\n",
      "Train Accuracy: 0.9534, F1 Score: 0.9531\n",
      "Epoch [17/30], Loss: 0.2528\n",
      "Train Accuracy: 0.9577, F1 Score: 0.9574\n",
      "Epoch [18/30], Loss: 0.2288\n",
      "Train Accuracy: 0.9608, F1 Score: 0.9606\n",
      "Epoch [19/30], Loss: 0.2067\n",
      "Train Accuracy: 0.9643, F1 Score: 0.9642\n",
      "Epoch [20/30], Loss: 0.1867\n",
      "Train Accuracy: 0.9672, F1 Score: 0.9672\n",
      "Epoch [21/30], Loss: 0.1686\n",
      "Train Accuracy: 0.9697, F1 Score: 0.9697\n",
      "Epoch [22/30], Loss: 0.1523\n",
      "Train Accuracy: 0.9726, F1 Score: 0.9726\n",
      "Epoch [23/30], Loss: 0.1376\n",
      "Train Accuracy: 0.9748, F1 Score: 0.9747\n",
      "Epoch [24/30], Loss: 0.1244\n",
      "Train Accuracy: 0.9771, F1 Score: 0.9771\n",
      "Epoch [25/30], Loss: 0.1125\n",
      "Train Accuracy: 0.9794, F1 Score: 0.9794\n",
      "Epoch [26/30], Loss: 0.1018\n",
      "Train Accuracy: 0.9815, F1 Score: 0.9815\n",
      "Epoch [27/30], Loss: 0.0922\n",
      "Train Accuracy: 0.9832, F1 Score: 0.9832\n",
      "Epoch [28/30], Loss: 0.0836\n",
      "Train Accuracy: 0.9850, F1 Score: 0.9850\n",
      "Epoch [29/30], Loss: 0.0758\n",
      "Train Accuracy: 0.9863, F1 Score: 0.9863\n",
      "Epoch [30/30], Loss: 0.0688\n",
      "[[12329   171]\n",
      " [  172 12328]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_data).squeeze(1)  # Ensure outputs are of shape [batch_size, 1]\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Compute accuracy and F1 score on the training set\n",
    "    with torch.no_grad():\n",
    "        preds = torch.round(torch.sigmoid(outputs))\n",
    "        acc = (preds == train_labels).float().mean().item()\n",
    "        # F1 score calculation\n",
    "        tp = ((preds == 1) & (train_labels == 1)).sum().item()\n",
    "        fp = ((preds == 1) & (train_labels == 0)).sum().item()\n",
    "        fn = ((preds == 0) & (train_labels == 1)).sum().item()\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        print(f\"Train Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(train_labels.cpu().numpy(), preds.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8b50c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4032, Test Accuracy: 0.8528, F1 Score: 0.8485\n",
      "[[11017  1483]\n",
      " [ 2197 10303]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_data).squeeze(1)  # Ensure the output is 1D\n",
    "    test_loss = criterion(test_outputs, test_labels)\n",
    "    predicted = torch.round(torch.sigmoid(test_outputs))\n",
    "    accuracy = (predicted == test_labels).float().mean()\n",
    "    \n",
    "    # F1 score calculation for the test set\n",
    "    tp = ((predicted == 1) & (test_labels == 1)).sum().item()\n",
    "    fp = ((predicted == 1) & (test_labels == 0)).sum().item()\n",
    "    fn = ((predicted == 0) & (test_labels == 1)).sum().item()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {accuracy.item():.4f}, F1 Score: {f1:.4f}')\n",
    "    print(confusion_matrix(test_labels.cpu().numpy(), predicted.cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
