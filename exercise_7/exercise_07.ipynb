{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d8f8dde9362918",
   "metadata": {},
   "source": [
    "# Exercise 7: Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19d974b513a6c0",
   "metadata": {},
   "source": [
    "Copy the data loading, vectorization and `SelfAttention` implementation from the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429e50f72e0e7bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twoface/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from gensim.downloader import load as gensim_load\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193458a8af39a9b",
   "metadata": {},
   "source": [
    "## C.1 Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d4d2761ff92370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse the `SelfAttention` class from Exercise 6, but you might need to extend it to support masking (C.1.1.v).\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_k, mask=None):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        self.WQ = nn.Linear(d_model, d_k)\n",
    "        self.WK = nn.Linear(d_model, d_k)\n",
    "        self.WV = nn.Linear(d_model, d_k)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        Q = self.WQ(x)\n",
    "        K = self.WK(x)\n",
    "        V = self.WV(x)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        probabilities = F.softmax(scores, dim=-1)\n",
    "        outputs = torch.matmul(probabilities, V)\n",
    "        \n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0350ceb3042e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.1.1 Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k if d_k is not None else d_model // n_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.WQ = nn.Linear(d_model, n_heads * self.d_k)\n",
    "        self.WK = nn.Linear(d_model, n_heads * self.d_k)\n",
    "        self.WV = nn.Linear(d_model, n_heads * self.d_k)\n",
    "        \n",
    "        self.WO = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        \n",
    "        # x shape : (batch_size, seq_len, d_model)\n",
    "        # Computing Q, K, V matrices. Shape: (batch_size, seq_len, n_heads * d_k)\n",
    "        Q = self.WQ(x)\n",
    "        K = self.WK(x)\n",
    "        V = self.WV(x)\n",
    "        \n",
    "        # Reshape to (batch_size, seq_len, n_heads, d_k), so that we can have n_heads attention heads for parallel computation\n",
    "        Q_reshaped = Q.view(batch_size, seq_len, self.n_heads, self.d_k)\n",
    "        K_reshaped = K.view(batch_size, seq_len, self.n_heads, self.d_k)\n",
    "        V_reshaped = V.view(batch_size, seq_len, self.n_heads, self.d_k)\n",
    "\n",
    "        # Transpose to (batch_size, n_heads, seq_len, d_k), utile pour la multiplication matricielle apres\n",
    "        Q_final = Q_reshaped.transpose(1, 2)\n",
    "        K_final = K_reshaped.transpose(1, 2)\n",
    "        V_final = V_reshaped.transpose(1, 2)\n",
    "        \n",
    "        # shape: (batch_size, n_heads, seq_len, seq_len), correspond a dire what is the score of each token with respect to each other token in the sequence\n",
    "        scores = torch.matmul(Q_final, K_final.transpose(-2, -1)) / np.sqrt(self.d_k) \n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2)  # Reshape mask to (batch_size, 1, 1, seq_len) as it was of shape (batch_size, seq_len)\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "            \n",
    "        probabilities = F.softmax(scores, dim=-1)\n",
    "        outputs = torch.matmul(probabilities, V_final) # shape: (batch_size, n_heads, seq_len, d_k)\n",
    "        outputs = outputs.transpose(1,2).contiguous()\n",
    "        \n",
    "        concatenated_outputs = outputs.view(batch_size, seq_len, self.d_model)\n",
    "        final_output = self.WO(concatenated_outputs)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0bac4442eb71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.1.2 Add Residual Connection and LayerNorm\n",
    "class MultiHeadBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads, d_k)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.attention(x, mask) + x # On a fait un + x pour avoir la Residual Connection\n",
    "        x = self.norm1(x) # On normalise le output\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e45c65880c8b0c",
   "metadata": {},
   "source": [
    "## C.2 Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50665a00d35ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.1 Point-wise Feed-Forward Network\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.expand_layer = nn.Linear(d_model, d_ff)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.reduce_layer = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.expand_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.reduce_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b86f3f16759dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2 \n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ff(x) + x # Residual connection\n",
    "        x = self.norm2(x) # Layer normalization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d7fa078c06bef",
   "metadata": {},
   "source": [
    "## Task 3: Encoder Block and Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e70ea40448194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the Encoder Block, i.e., the combination of MultiHeadBlock and FeedForwardBlock\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, d_k=None):\n",
    "        super().__init__()\n",
    "        self.multi_head_block = MultiHeadBlock(d_model=d_model, n_heads = n_heads, d_k = d_k)\n",
    "        self.feed_forward_block = FeedForwardBlock(d_model=d_model, d_ff = d_ff)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.multi_head_block(x, mask)  # Multi-head attention block\n",
    "        x = self.feed_forward_block(x)  # Feed-forward block\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67c1985cf512540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_heads, d_ff, max_len = 512, d_k=None, num_classes=2, n_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.d_model = d_model\n",
    "        self.word_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_embedding = nn.Embedding(max_len, d_model)  # Positional embeddings for sequence order\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [EncoderBlock(d_model = d_model, n_heads = n_heads, d_ff = d_ff, d_k = d_k) for _ in range(n_layers)]\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        # todo\n",
    "\n",
    "    def forward(self, x_ids, mask=None):\n",
    "        batch_size, seq_len = x_ids.shape\n",
    "        positions = torch.arange(0,seq_len, device=x_ids.device)\n",
    "        x = self.word_embedding(x_ids) + self.positional_embedding(positions)\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x, mask)\n",
    "        x = x[:,0,:]  # Assuming we take the first token's representation for classification\n",
    "        x = self.classifier(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2a0d103dccaf1",
   "metadata": {},
   "source": [
    "## Task 4: Data Preparation (same as in Exercise 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec21b969f1ecad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = gensim_load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5540f876aca31a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb(n_samples=100):\n",
    "    dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "    # How many samples per class\n",
    "    n_per_class = n_samples // 2\n",
    "\n",
    "    # Filter each class\n",
    "    pos = dataset.filter(lambda x: x[\"label\"] == 1).shuffle(seed=42).select(range(n_per_class))\n",
    "    neg = dataset.filter(lambda x: x[\"label\"] == 0).shuffle(seed=42).select(range(n_per_class))\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    balanced = concatenate_datasets([pos, neg]).shuffle(seed=42)\n",
    "\n",
    "    texts = balanced[\"text\"]\n",
    "    labels = balanced[\"label\"]\n",
    "    return texts, labels\n",
    "\n",
    "texts, labels = load_imdb(n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5ed085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts_list = list(texts)\n",
    "labels_list = list(labels)\n",
    "\n",
    "# Now your original code will work perfectly\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts_list, \n",
    "    labels_list, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=labels_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc82121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokenized_texts):\n",
    "    all_tokens = [token for text in tokenized_texts for token in text]\n",
    "    unique_tokens = set(all_tokens)\n",
    "    \n",
    "    vocab = {\n",
    "        '[PAD]': 0,\n",
    "        '[UNK]': 1,\n",
    "        '[CLS]': 2,\n",
    "        '[SEP]': 3,\n",
    "    }\n",
    "    \n",
    "    for i, token in enumerate(unique_tokens, start=4):\n",
    "        vocab[token] = i\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c80deeac5c59da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/twoface/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/twoface/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def tokenize(text):\n",
    "    return [w.lower() for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d09fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_special_tokens(tokens, max_len=128):\n",
    "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "    if len(tokens) > max_len:\n",
    "        tokens = tokens[:max_len]\n",
    "    while len(tokens) < max_len:\n",
    "        tokens.append(\"[PAD]\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc93ba78dfeab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tokens, max_len=128):\n",
    "    embed_dim = glove.vector_size\n",
    "    vecs = []\n",
    "    for token in tokens[:max_len]:\n",
    "        vec = glove[token] if token in glove else np.zeros(embed_dim)\n",
    "        vecs.append(vec)\n",
    "    while len(vecs) < max_len:\n",
    "        vecs.append(np.zeros(embed_dim))\n",
    "    return np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d5d09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask(tokens):\n",
    "    # tokens is the list of tokens *after* adding special tokens and padding\n",
    "    return [1 if token != \"[PAD]\" else 0 for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc3b4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, vocab, max_len=128):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = add_special_tokens(tokens, max_len)\n",
    "    mask = create_attention_mask(tokens)\n",
    "    ids = [vocab.get(token, vocab['[UNK]']) for token in tokens]\n",
    "    return np.array(ids), np.array(mask)\n",
    "\n",
    "def preprocess(texts, vocab, max_len=128):\n",
    "    all_token_ids = []\n",
    "    all_attention_masks = []\n",
    "    \n",
    "    for text in texts:\n",
    "        tokens = tokenize(text)\n",
    "        tokens = add_special_tokens(tokens, max_len)\n",
    "        mask = create_attention_mask(tokens)\n",
    "        all_attention_masks.append(mask)\n",
    "        \n",
    "        ids = [vocab.get(token, vocab['[UNK]']) for token in tokens]\n",
    "        all_token_ids.append(ids)\n",
    "\n",
    "    return np.array(all_token_ids), np.array(all_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5bc748f628d6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "max_len = 128\n",
    "vocab = build_vocab([tokenize(text) for text in train_texts])\n",
    "train_token_ids, train_masks = preprocess(train_texts, vocab, max_len)\n",
    "X_train = torch.tensor(train_token_ids, dtype=torch.long)\n",
    "y_train = torch.tensor(train_labels, dtype=torch.long)\n",
    "masks_train = torch.tensor(train_masks, dtype=torch.long)\n",
    "\n",
    "val_token_ids, val_masks = preprocess(val_texts, vocab, max_len)\n",
    "X_val = torch.tensor(val_token_ids, dtype=torch.long)\n",
    "y_val = torch.tensor(val_labels, dtype=torch.long)\n",
    "masks_val = torch.tensor(val_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145f54fb61c09ad",
   "metadata": {},
   "source": [
    "## Task 5: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c28d41979cc101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose your model parameters\n",
    "# Remember the rules of thumb:\n",
    "# - d_ff = 4*d_model\n",
    "# - d_k = d_model // n_heads \n",
    "\n",
    "vocab_size = len(vocab)\n",
    "d_model = 128\n",
    "n_heads = 8\n",
    "d_ff = 4 * d_model\n",
    "d_k = d_model // n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d23cb432b8e676a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (word_embedding): Embedding(62177, 128)\n",
       "  (positional_embedding): Embedding(512, 128)\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0-2): 3 x EncoderBlock(\n",
       "      (multi_head_block): MultiHeadBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (WK): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (WV): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (WO): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward_block): FeedForwardBlock(\n",
       "        (ff): FeedForward(\n",
       "          (expand_layer): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (activation): ReLU()\n",
       "          (reduce_layer): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model, loss, optimizer\n",
    "# todo\n",
    "model = SentimentClassifier(vocab_size=vocab_size, d_model=d_model, n_heads=n_heads, d_ff=d_ff, d_k=d_k, n_layers=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "957c4e3c87442fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 8,619,266\n",
      "Model parameters relative to BERT base: 7.835696%\n",
      "Model parameters relative to GPT-4: 0.000507%\n"
     ]
    }
   ],
   "source": [
    "# print the total parameter count of the model\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "bert_base_params = 110_000_000  # BERT base model has ~110M parameters\n",
    "gpt_4_params = 1_700_000_000_000  # GPT-4 has ~1.7T parameters\n",
    "print(f\"Model parameters relative to BERT base: {100 * total_params / bert_base_params:.6f}%\")\n",
    "print(f\"Model parameters relative to GPT-4: {100 * total_params / gpt_4_params:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8edd5ff0330aaa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (word_embedding): Embedding(62177, 128)\n",
       "  (positional_embedding): Embedding(512, 128)\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0-2): 3 x EncoderBlock(\n",
       "      (multi_head_block): MultiHeadBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (WK): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (WV): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (WO): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward_block): FeedForwardBlock(\n",
       "        (ff): FeedForward(\n",
       "          (expand_layer): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (activation): ReLU()\n",
       "          (reduce_layer): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the training loop\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = TensorDataset(X_train, masks_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, masks_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21271e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/5: 100%|██████████| 250/250 [00:05<00:00, 46.18it/s]\n",
      "Training Epoch 1/5: 100%|██████████| 250/250 [00:05<00:00, 46.18it/s]\n",
      "Validation Epoch 1/5: 100%|██████████| 63/63 [00:00<00:00, 184.98it/s]\n",
      "Validation Epoch 1/5: 100%|██████████| 63/63 [00:00<00:00, 184.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "  Train Loss: 0.6901\n",
      "  Val Loss: 0.6726\n",
      "  Val Accuracy: 0.5685\n",
      "  Val F1-Score: 0.5057\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/5: 100%|██████████| 250/250 [00:04<00:00, 50.56it/s]\n",
      "Training Epoch 2/5: 100%|██████████| 250/250 [00:04<00:00, 50.56it/s]\n",
      "Validation Epoch 2/5: 100%|██████████| 63/63 [00:00<00:00, 190.10it/s]\n",
      "Validation Epoch 2/5: 100%|██████████| 63/63 [00:00<00:00, 190.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:\n",
      "  Train Loss: 0.6363\n",
      "  Val Loss: 0.6186\n",
      "  Val Accuracy: 0.6455\n",
      "  Val F1-Score: 0.6286\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/5: 100%|██████████| 250/250 [00:04<00:00, 54.22it/s]\n",
      "Training Epoch 3/5: 100%|██████████| 250/250 [00:04<00:00, 54.22it/s]\n",
      "Validation Epoch 3/5: 100%|██████████| 63/63 [00:00<00:00, 202.05it/s]\n",
      "Validation Epoch 3/5: 100%|██████████| 63/63 [00:00<00:00, 202.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:\n",
      "  Train Loss: 0.5733\n",
      "  Val Loss: 0.5616\n",
      "  Val Accuracy: 0.7030\n",
      "  Val F1-Score: 0.7019\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/5: 100%|██████████| 250/250 [00:04<00:00, 54.37it/s]\n",
      "Training Epoch 4/5: 100%|██████████| 250/250 [00:04<00:00, 54.37it/s]\n",
      "Validation Epoch 4/5: 100%|██████████| 63/63 [00:00<00:00, 197.15it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:\n",
      "  Train Loss: 0.5100\n",
      "  Val Loss: 0.5589\n",
      "  Val Accuracy: 0.7120\n",
      "  Val F1-Score: 0.7097\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/5: 100%|██████████| 250/250 [00:04<00:00, 53.78it/s]\n",
      "Training Epoch 5/5: 100%|██████████| 250/250 [00:04<00:00, 53.78it/s]\n",
      "Validation Epoch 5/5: 100%|██████████| 63/63 [00:00<00:00, 190.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:\n",
      "  Train Loss: 0.4433\n",
      "  Val Loss: 0.5859\n",
      "  Val Accuracy: 0.7085\n",
      "  Val F1-Score: 0.7048\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
    "        batch_x = batch[0].to(device)  # Token IDs\n",
    "        batch_masks = batch[1].to(device)  # Attention masks\n",
    "        batch_y = batch[2].to(device)  # Labels\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_x, mask=batch_masks)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
    "            batch_x = batch[0].to(device)\n",
    "            batch_masks = batch[1].to(device)\n",
    "            batch_y = batch[2].to(device)\n",
    "            \n",
    "            outputs = model(batch_x, mask=batch_masks)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Val Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Val F1-Score: {f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fa3d20d04d151",
   "metadata": {},
   "source": [
    "## Task 6: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "373c787c59cf99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_sentiment(text, model = model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        token_ids, attention_mask = preprocess_text(text, vocab, max_len=128)\n",
    "        token_ids = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        attention_mask = torch.tensor(attention_mask, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        outputs = model(token_ids, mask=attention_mask)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        \n",
    "    prediction = \"Positive\" if predicted_class == 1 else \"Negative\"\n",
    "    probability = probabilities[0][predicted_class].item()\n",
    "    return prediction, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f802f6080ece39ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', 0.9527169466018677)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"I love this movie! It's fantastic and uplifting.\")  # Should return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1b7a8dcd00747a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Negative', 0.9466676115989685)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"This movie was terrible. I hated it.\")  # Should return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edacf864767b751d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', 0.8370497822761536)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"I didn't like the ending, but I love the music.\") # Mixed sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a67b0cb78c751ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Negative', 0.8841147422790527)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"I didn't like the ending.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7470c75d7ca3ca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', 0.7118408679962158)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"i love the music.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8712c9585c93221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', 0.934095561504364)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"but i love the music.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ba92dd20348db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', 0.849819540977478)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"i love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c8367b5a03bebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', 0.5293876528739929)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"well... I guess it was okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94657635db294566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Negative', 0.9960319399833679)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_review_sentiment(\"movie was terrible, very bad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
