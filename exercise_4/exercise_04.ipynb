{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e944d31a1f9c682",
   "metadata": {},
   "source": [
    "# Exercise 4: Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5900bf44d5dc72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "DATASET_PATH = os.path.join('..', 'datasets', 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190ea7ab837c69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(item):\n",
    "    \"\"\" Function tha gets only the first number of the name of the file and organizes the files base on that\"\"\"\n",
    "    \n",
    "    return int(os.path.basename(item).split('_')[0])\n",
    "\n",
    "def read_raw_text(path_data):\n",
    "    \"\"\" Function for reading the raw data in the .txt files. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_data: str\n",
    "        path of the folder that contains the data that is going to be used. (should be test or train)\n",
    "    path_vocab_pos: str, optional\n",
    "        Glob pattern for the data files. If None, defaults to standard IMDB structure.\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    data,scores: array_like\n",
    "        Data arrays, X is an array of shape [#documents of the dataset, #words in the vocabulary], y is an array of shape [#documents,] \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    scores = []\n",
    "    \n",
    "    sentiments = ['pos', 'neg']\n",
    "    for sentiment in sentiments:\n",
    "        path_vocab_pos = os.path.join(DATASET_PATH, path_data, sentiment, \"*.txt\")\n",
    "        for filename in sorted(glob.glob(path_vocab_pos), key=sorter):\n",
    "            with open(filename, encoding='utf8') as f:\n",
    "                lines = f.read()\n",
    "                data.append(lines)\n",
    "                scores.append(int(os.path.basename(filename).split('_')[1].strip('.txt')))\n",
    "    return data, scores\n",
    "\n",
    "def read_vocab(path_vocab):\n",
    "    \"\"\" Function for reading the vocabulary file. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_vocab: str\n",
    "        Path to the vocabulary file.\n",
    "    Returns\n",
    "    ---------\n",
    "    initial_vocab: list\n",
    "        list with the values different tokens that compose the vocabulary ...... \n",
    "    \"\"\"\n",
    "    with open(path_vocab, encoding='utf-8') as f:\n",
    "        lines = f.read()\n",
    "    lines = lines.split('\\n')\n",
    "    vocab = []\n",
    "    for line in lines:\n",
    "        vocab.append(line)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55133a24be572934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "from utils.preprocess import load_data_to_df\n",
    "\n",
    "\n",
    "corpus, scores = read_raw_text('train')\n",
    "corpus_df = load_data_to_df(corpus, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fc9d82d39de68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from utils.preprocess import pre_process\n",
    "\n",
    "tokenized_corpus = pre_process(corpus_df, tokenize_punct=True, lowercase=True, remove_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755f7b4069b6260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  score  \\\n",
      "0    bromwell high is a cartoon comedy  it ran at t...      9   \n",
      "1    if you like adult comedy cartoons  like south ...      7   \n",
      "2    bromwell high is nothing short of brilliant  e...      9   \n",
      "3     all the world s a stage and its people actors...     10   \n",
      "4    futz is the only show preserved from the exper...      8   \n",
      "..                                                 ...    ...   \n",
      "995  this movie surprised me  some things were  cli...      9   \n",
      "996  this movie surprised me  some things were  cli...      9   \n",
      "997  i have to agree with most of the other posts  ...      7   \n",
      "998  this is a really interesting movie  it is an a...      7   \n",
      "999  i am amazed at how this movie and most others ...     10   \n",
      "\n",
      "                                                tokens  \n",
      "0    [bromwell, high, is, a, cartoon, comedy, it, r...  \n",
      "1    [if, you, like, adult, comedy, cartoons, like,...  \n",
      "2    [bromwell, high, is, nothing, short, of, brill...  \n",
      "3    [all, the, world, s, a, stage, and, its, peopl...  \n",
      "4    [futz, is, the, only, show, preserved, from, t...  \n",
      "..                                                 ...  \n",
      "995  [this, movie, surprised, me, some, things, wer...  \n",
      "996  [this, movie, surprised, me, some, things, wer...  \n",
      "997  [i, have, to, agree, with, most, of, the, othe...  \n",
      "998  [this, is, a, really, interesting, movie, it, ...  \n",
      "999  [i, am, amazed, at, how, this, movie, and, mos...  \n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# reduce the corpus if you are facing performance issues\n",
    "tokenized_corpus = tokenized_corpus[:1000]  # reduce to first 1000 documents for testing\n",
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc156b148c732d4",
   "metadata": {},
   "source": [
    "## Task 1: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afc8ca6d284bf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size 16016\n",
      "Context Size 2\n",
      "Embedding Dimension 10\n"
     ]
    }
   ],
   "source": [
    "# Parameters (change these as wanted)\n",
    "CONTEXT_SIZE = 2  # Window size on each side\n",
    "EMBEDDING_DIM = 10\n",
    "PAD_TOKEN = '<PAD>'\n",
    "\n",
    "# Vocabulary\n",
    "# Build vocabulary from all tokens in the tokenized_corpus DataFrame\n",
    "vocab = sorted(set(token for tokens in tokenized_corpus['tokens'] for token in tokens))\n",
    "if PAD_TOKEN not in vocab:\n",
    "    vocab.append(PAD_TOKEN)\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocab Size', vocab_size)\n",
    "print('Context Size', CONTEXT_SIZE)\n",
    "print('Embedding Dimension', EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0d180b5bc84ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0',\n",
       " 1: '00',\n",
       " 2: '000',\n",
       " 3: '000s',\n",
       " 4: '007',\n",
       " 5: '0079',\n",
       " 6: '0080',\n",
       " 7: '0083',\n",
       " 8: '00pm',\n",
       " 9: '01',\n",
       " 10: '02',\n",
       " 11: '06',\n",
       " 12: '1',\n",
       " 13: '10',\n",
       " 14: '100',\n",
       " 15: '10000000000000',\n",
       " 16: '101',\n",
       " 17: '10th',\n",
       " 18: '11',\n",
       " 19: '1100',\n",
       " 20: '12',\n",
       " 21: '128',\n",
       " 22: '12th',\n",
       " 23: '13',\n",
       " 24: '135',\n",
       " 25: '13th',\n",
       " 26: '14',\n",
       " 27: '14th',\n",
       " 28: '15',\n",
       " 29: '150',\n",
       " 30: '16',\n",
       " 31: '17',\n",
       " 32: '18',\n",
       " 33: '1800',\n",
       " 34: '1830',\n",
       " 35: '1836',\n",
       " 36: '1838',\n",
       " 37: '1846',\n",
       " 38: '1850s',\n",
       " 39: '1853',\n",
       " 40: '1854',\n",
       " 41: '1855',\n",
       " 42: '1860',\n",
       " 43: '1862',\n",
       " 44: '1896',\n",
       " 45: '18th',\n",
       " 46: '19',\n",
       " 47: '1909',\n",
       " 48: '1910',\n",
       " 49: '1920',\n",
       " 50: '1920s',\n",
       " 51: '1924',\n",
       " 52: '1928',\n",
       " 53: '1929',\n",
       " 54: '1930',\n",
       " 55: '1930s',\n",
       " 56: '1931',\n",
       " 57: '1933',\n",
       " 58: '1935',\n",
       " 59: '1936',\n",
       " 60: '1938',\n",
       " 61: '1939',\n",
       " 62: '1940',\n",
       " 63: '1940s',\n",
       " 64: '1944',\n",
       " 65: '1945',\n",
       " 66: '1946',\n",
       " 67: '1947',\n",
       " 68: '1948',\n",
       " 69: '1950',\n",
       " 70: '1950s',\n",
       " 71: '1951',\n",
       " 72: '1952',\n",
       " 73: '1953',\n",
       " 74: '1954',\n",
       " 75: '1955',\n",
       " 76: '1956',\n",
       " 77: '1957',\n",
       " 78: '1958',\n",
       " 79: '1959',\n",
       " 80: '1960',\n",
       " 81: '1960s',\n",
       " 82: '1961',\n",
       " 83: '1963',\n",
       " 84: '1964',\n",
       " 85: '1966',\n",
       " 86: '1968',\n",
       " 87: '1969',\n",
       " 88: '1970',\n",
       " 89: '1970s',\n",
       " 90: '1971',\n",
       " 91: '1972',\n",
       " 92: '1973',\n",
       " 93: '1974',\n",
       " 94: '1975',\n",
       " 95: '1976',\n",
       " 96: '1977',\n",
       " 97: '1979',\n",
       " 98: '1980',\n",
       " 99: '1980s',\n",
       " 100: '1981',\n",
       " 101: '1982',\n",
       " 102: '1983',\n",
       " 103: '1984',\n",
       " 104: '1985',\n",
       " 105: '1986',\n",
       " 106: '1987',\n",
       " 107: '1988',\n",
       " 108: '1989',\n",
       " 109: '1990',\n",
       " 110: '1990s',\n",
       " 111: '1991',\n",
       " 112: '1992',\n",
       " 113: '1993',\n",
       " 114: '1994',\n",
       " 115: '1995',\n",
       " 116: '1996',\n",
       " 117: '1997',\n",
       " 118: '1998',\n",
       " 119: '1999',\n",
       " 120: '19th',\n",
       " 121: '1h40',\n",
       " 122: '1st',\n",
       " 123: '1½',\n",
       " 124: '2',\n",
       " 125: '20',\n",
       " 126: '200',\n",
       " 127: '2000',\n",
       " 128: '2001',\n",
       " 129: '2002',\n",
       " 130: '2003',\n",
       " 131: '2004',\n",
       " 132: '2005',\n",
       " 133: '2006',\n",
       " 134: '2007',\n",
       " 135: '2008',\n",
       " 136: '2009',\n",
       " 137: '2040',\n",
       " 138: '20s',\n",
       " 139: '20th',\n",
       " 140: '21',\n",
       " 141: '210',\n",
       " 142: '215',\n",
       " 143: '2151',\n",
       " 144: '22',\n",
       " 145: '2200',\n",
       " 146: '24',\n",
       " 147: '24th',\n",
       " 148: '25',\n",
       " 149: '250',\n",
       " 150: '25th',\n",
       " 151: '26',\n",
       " 152: '27',\n",
       " 153: '28',\n",
       " 154: '2d',\n",
       " 155: '2nd',\n",
       " 156: '3',\n",
       " 157: '30',\n",
       " 158: '300mln',\n",
       " 159: '30lbs',\n",
       " 160: '30mins',\n",
       " 161: '30pm',\n",
       " 162: '30s',\n",
       " 163: '31',\n",
       " 164: '32',\n",
       " 165: '33',\n",
       " 166: '34th',\n",
       " 167: '35',\n",
       " 168: '35mm',\n",
       " 169: '36',\n",
       " 170: '370',\n",
       " 171: '3d',\n",
       " 172: '3p0',\n",
       " 173: '3po',\n",
       " 174: '3rd',\n",
       " 175: '4',\n",
       " 176: '40',\n",
       " 177: '42nd',\n",
       " 178: '43',\n",
       " 179: '45',\n",
       " 180: '46',\n",
       " 181: '47',\n",
       " 182: '48',\n",
       " 183: '4th',\n",
       " 184: '5',\n",
       " 185: '50',\n",
       " 186: '500',\n",
       " 187: '50s',\n",
       " 188: '51',\n",
       " 189: '52',\n",
       " 190: '54',\n",
       " 191: '56',\n",
       " 192: '576',\n",
       " 193: '58',\n",
       " 194: '59',\n",
       " 195: '6',\n",
       " 196: '60',\n",
       " 197: '60s',\n",
       " 198: '64',\n",
       " 199: '65',\n",
       " 200: '68',\n",
       " 201: '6hours',\n",
       " 202: '6th',\n",
       " 203: '7',\n",
       " 204: '70',\n",
       " 205: '70s',\n",
       " 206: '71',\n",
       " 207: '73',\n",
       " 208: '75',\n",
       " 209: '78',\n",
       " 210: '79',\n",
       " 211: '7ft',\n",
       " 212: '7th',\n",
       " 213: '8',\n",
       " 214: '80',\n",
       " 215: '80s',\n",
       " 216: '84',\n",
       " 217: '85',\n",
       " 218: '86',\n",
       " 219: '89',\n",
       " 220: '8pm',\n",
       " 221: '8th',\n",
       " 222: '9',\n",
       " 223: '90',\n",
       " 224: '900',\n",
       " 225: '90s',\n",
       " 226: '93',\n",
       " 227: '95',\n",
       " 228: '96',\n",
       " 229: '97',\n",
       " 230: '99',\n",
       " 231: '9pm',\n",
       " 232: 'a',\n",
       " 233: 'aachen',\n",
       " 234: 'aada',\n",
       " 235: 'aadha',\n",
       " 236: 'aamir',\n",
       " 237: 'aapke',\n",
       " 238: 'aapkey',\n",
       " 239: 'aaron',\n",
       " 240: 'ab',\n",
       " 241: 'aback',\n",
       " 242: 'abandon',\n",
       " 243: 'abandoned',\n",
       " 244: 'abandonment',\n",
       " 245: 'abandons',\n",
       " 246: 'abbreviated',\n",
       " 247: 'abby',\n",
       " 248: 'abc',\n",
       " 249: 'abduct',\n",
       " 250: 'abductor',\n",
       " 251: 'abe',\n",
       " 252: 'abhi',\n",
       " 253: 'abiding',\n",
       " 254: 'abilities',\n",
       " 255: 'ability',\n",
       " 256: 'able',\n",
       " 257: 'abo',\n",
       " 258: 'aboard',\n",
       " 259: 'abominable',\n",
       " 260: 'abomination',\n",
       " 261: 'aborigin',\n",
       " 262: 'aboriginal',\n",
       " 263: 'aboriginals',\n",
       " 264: 'aborigine',\n",
       " 265: 'aborigines',\n",
       " 266: 'aboriginies',\n",
       " 267: 'aborigins',\n",
       " 268: 'aborigone',\n",
       " 269: 'aborted',\n",
       " 270: 'abound',\n",
       " 271: 'about',\n",
       " 272: 'aboutagirly',\n",
       " 273: 'above',\n",
       " 274: 'abraham',\n",
       " 275: 'abroad',\n",
       " 276: 'abrupt',\n",
       " 277: 'abruptly',\n",
       " 278: 'abscond',\n",
       " 279: 'absence',\n",
       " 280: 'absent',\n",
       " 281: 'absentee',\n",
       " 282: 'absentminded',\n",
       " 283: 'absolute',\n",
       " 284: 'absolutely',\n",
       " 285: 'absorbed',\n",
       " 286: 'absorbing',\n",
       " 287: 'absorbs',\n",
       " 288: 'absorption',\n",
       " 289: 'abstained',\n",
       " 290: 'abstract',\n",
       " 291: 'abstraction',\n",
       " 292: 'absurd',\n",
       " 293: 'absurdism',\n",
       " 294: 'absurdist',\n",
       " 295: 'absurdity',\n",
       " 296: 'abundance',\n",
       " 297: 'abuse',\n",
       " 298: 'abused',\n",
       " 299: 'abusive',\n",
       " 300: 'academy',\n",
       " 301: 'acc',\n",
       " 302: 'accedes',\n",
       " 303: 'accelerated',\n",
       " 304: 'accent',\n",
       " 305: 'accented',\n",
       " 306: 'accents',\n",
       " 307: 'accentuates',\n",
       " 308: 'accept',\n",
       " 309: 'acceptable',\n",
       " 310: 'acceptance',\n",
       " 311: 'accepted',\n",
       " 312: 'accepting',\n",
       " 313: 'access',\n",
       " 314: 'accessible',\n",
       " 315: 'accident',\n",
       " 316: 'accidental',\n",
       " 317: 'accidentally',\n",
       " 318: 'accidents',\n",
       " 319: 'acclaim',\n",
       " 320: 'acclaimed',\n",
       " 321: 'acclamation',\n",
       " 322: 'accolades',\n",
       " 323: 'accompanied',\n",
       " 324: 'accompaniment',\n",
       " 325: 'accompany',\n",
       " 326: 'accomplish',\n",
       " 327: 'accomplished',\n",
       " 328: 'accomplishment',\n",
       " 329: 'accomplishments',\n",
       " 330: 'accord',\n",
       " 331: 'accorded',\n",
       " 332: 'accordian',\n",
       " 333: 'according',\n",
       " 334: 'accordion',\n",
       " 335: 'account',\n",
       " 336: 'accountability',\n",
       " 337: 'accounts',\n",
       " 338: 'accumulated',\n",
       " 339: 'accuracy',\n",
       " 340: 'accurate',\n",
       " 341: 'accurately',\n",
       " 342: 'accused',\n",
       " 343: 'accuses',\n",
       " 344: 'accustomed',\n",
       " 345: 'ace',\n",
       " 346: 'achieve',\n",
       " 347: 'achieved',\n",
       " 348: 'achievement',\n",
       " 349: 'achievements',\n",
       " 350: 'achievers',\n",
       " 351: 'achieves',\n",
       " 352: 'achieving',\n",
       " 353: 'achilles',\n",
       " 354: 'aching',\n",
       " 355: 'achingly',\n",
       " 356: 'achterbusch',\n",
       " 357: 'acidic',\n",
       " 358: 'acidity',\n",
       " 359: 'acknowledge',\n",
       " 360: 'acknowledged',\n",
       " 361: 'acknowledgement',\n",
       " 362: 'acknowledges',\n",
       " 363: 'acquaintance',\n",
       " 364: 'acquaintances',\n",
       " 365: 'acquainted',\n",
       " 366: 'acquire',\n",
       " 367: 'acquired',\n",
       " 368: 'acrimonious',\n",
       " 369: 'acrobatic',\n",
       " 370: 'across',\n",
       " 371: 'act',\n",
       " 372: 'acted',\n",
       " 373: 'actess',\n",
       " 374: 'acting',\n",
       " 375: 'action',\n",
       " 376: 'actioner',\n",
       " 377: 'actions',\n",
       " 378: 'active',\n",
       " 379: 'actively',\n",
       " 380: 'activism',\n",
       " 381: 'activities',\n",
       " 382: 'activity',\n",
       " 383: 'actor',\n",
       " 384: 'actors',\n",
       " 385: 'actress',\n",
       " 386: 'actresses',\n",
       " 387: 'acts',\n",
       " 388: 'actual',\n",
       " 389: 'actuality',\n",
       " 390: 'actually',\n",
       " 391: 'acutely',\n",
       " 392: 'ad',\n",
       " 393: 'ada',\n",
       " 394: 'adam',\n",
       " 395: 'adamant',\n",
       " 396: 'adapt',\n",
       " 397: 'adaptation',\n",
       " 398: 'adaptations',\n",
       " 399: 'adapted',\n",
       " 400: 'adapting',\n",
       " 401: 'adaption',\n",
       " 402: 'add',\n",
       " 403: 'added',\n",
       " 404: 'addict',\n",
       " 405: 'addicted',\n",
       " 406: 'addiction',\n",
       " 407: 'adding',\n",
       " 408: 'addition',\n",
       " 409: 'additional',\n",
       " 410: 'additions',\n",
       " 411: 'address',\n",
       " 412: 'addressed',\n",
       " 413: 'addressing',\n",
       " 414: 'adds',\n",
       " 415: 'adept',\n",
       " 416: 'adeptness',\n",
       " 417: 'adequate',\n",
       " 418: 'adherence',\n",
       " 419: 'adhura',\n",
       " 420: 'adjournment',\n",
       " 421: 'adjuncts',\n",
       " 422: 'adjusted',\n",
       " 423: 'adjuster',\n",
       " 424: 'adjustments',\n",
       " 425: 'administration',\n",
       " 426: 'administrative',\n",
       " 427: 'administrator',\n",
       " 428: 'admirable',\n",
       " 429: 'admiration',\n",
       " 430: 'admire',\n",
       " 431: 'admired',\n",
       " 432: 'admirers',\n",
       " 433: 'admiring',\n",
       " 434: 'admission',\n",
       " 435: 'admit',\n",
       " 436: 'admits',\n",
       " 437: 'admitted',\n",
       " 438: 'admittedly',\n",
       " 439: 'adolescence',\n",
       " 440: 'adolescent',\n",
       " 441: 'adolescents',\n",
       " 442: 'adolph',\n",
       " 443: 'adopted',\n",
       " 444: 'adoption',\n",
       " 445: 'adopts',\n",
       " 446: 'adorable',\n",
       " 447: 'adorably',\n",
       " 448: 'adore',\n",
       " 449: 'adored',\n",
       " 450: 'adoree',\n",
       " 451: 'adoring',\n",
       " 452: 'adrenaline',\n",
       " 453: 'adrian',\n",
       " 454: 'adroit',\n",
       " 455: 'ads',\n",
       " 456: 'adult',\n",
       " 457: 'adulthood',\n",
       " 458: 'adults',\n",
       " 459: 'advance',\n",
       " 460: 'advanced',\n",
       " 461: 'advancement',\n",
       " 462: 'advancements',\n",
       " 463: 'advances',\n",
       " 464: 'advancing',\n",
       " 465: 'advantage',\n",
       " 466: 'advantages',\n",
       " 467: 'adventure',\n",
       " 468: 'adventures',\n",
       " 469: 'adversary',\n",
       " 470: 'advertised',\n",
       " 471: 'advertising',\n",
       " 472: 'adverts',\n",
       " 473: 'advice',\n",
       " 474: 'advices',\n",
       " 475: 'advised',\n",
       " 476: 'advocate',\n",
       " 477: 'aesthetic',\n",
       " 478: 'aesthetically',\n",
       " 479: 'afar',\n",
       " 480: 'affable',\n",
       " 481: 'affair',\n",
       " 482: 'affairs',\n",
       " 483: 'affect',\n",
       " 484: 'affectations',\n",
       " 485: 'affected',\n",
       " 486: 'affecting',\n",
       " 487: 'affection',\n",
       " 488: 'affectionate',\n",
       " 489: 'affects',\n",
       " 490: 'afficinados',\n",
       " 491: 'affiliation',\n",
       " 492: 'affluent',\n",
       " 493: 'afford',\n",
       " 494: 'afforded',\n",
       " 495: 'affords',\n",
       " 496: 'aficionado',\n",
       " 497: 'aficionados',\n",
       " 498: 'aforesaid',\n",
       " 499: 'afraid',\n",
       " 500: 'africa',\n",
       " 501: 'african',\n",
       " 502: 'afrika',\n",
       " 503: 'after',\n",
       " 504: 'aftereffects',\n",
       " 505: 'afterlife',\n",
       " 506: 'aftermath',\n",
       " 507: 'afternoon',\n",
       " 508: 'afterward',\n",
       " 509: 'afterwards',\n",
       " 510: 'afterworld',\n",
       " 511: 'aftra',\n",
       " 512: 'again',\n",
       " 513: 'against',\n",
       " 514: 'agatha',\n",
       " 515: 'age',\n",
       " 516: 'aged',\n",
       " 517: 'ageing',\n",
       " 518: 'agency',\n",
       " 519: 'agenda',\n",
       " 520: 'agendas',\n",
       " 521: 'agent',\n",
       " 522: 'agents',\n",
       " 523: 'ager',\n",
       " 524: 'ages',\n",
       " 525: 'aggravated',\n",
       " 526: 'aggression',\n",
       " 527: 'aggressive',\n",
       " 528: 'aggressively',\n",
       " 529: 'aghast',\n",
       " 530: 'aghhh',\n",
       " 531: 'agi',\n",
       " 532: 'agin',\n",
       " 533: 'aging',\n",
       " 534: 'agitated',\n",
       " 535: 'agnieszka',\n",
       " 536: 'agniezska',\n",
       " 537: 'ago',\n",
       " 538: 'agony',\n",
       " 539: 'agree',\n",
       " 540: 'agreed',\n",
       " 541: 'agrees',\n",
       " 542: 'agusti',\n",
       " 543: 'agustí',\n",
       " 544: 'ah',\n",
       " 545: 'ahead',\n",
       " 546: 'ahem',\n",
       " 547: 'ahh',\n",
       " 548: 'ahhh',\n",
       " 549: 'ahlstedt',\n",
       " 550: 'aid',\n",
       " 551: 'aide',\n",
       " 552: 'aided',\n",
       " 553: 'aides',\n",
       " 554: 'aids',\n",
       " 555: 'aileen',\n",
       " 556: 'ailing',\n",
       " 557: 'ailments',\n",
       " 558: 'aim',\n",
       " 559: 'aimed',\n",
       " 560: 'aimee',\n",
       " 561: 'aiming',\n",
       " 562: 'aimlessly',\n",
       " 563: 'ain',\n",
       " 564: 'air',\n",
       " 565: 'aircraft',\n",
       " 566: 'aired',\n",
       " 567: 'airing',\n",
       " 568: 'airman',\n",
       " 569: 'airplane',\n",
       " 570: 'airs',\n",
       " 571: 'aisle',\n",
       " 572: 'ajay',\n",
       " 573: 'ajnabe',\n",
       " 574: 'ajnabi',\n",
       " 575: 'aka',\n",
       " 576: 'akin',\n",
       " 577: 'akira',\n",
       " 578: 'akosua',\n",
       " 579: 'akuzi',\n",
       " 580: 'al',\n",
       " 581: 'ala',\n",
       " 582: 'alain',\n",
       " 583: 'alamo',\n",
       " 584: 'alan',\n",
       " 585: 'alarmed',\n",
       " 586: 'alarming',\n",
       " 587: 'alas',\n",
       " 588: 'alaska',\n",
       " 589: 'alaskan',\n",
       " 590: 'alastair',\n",
       " 591: 'albanian',\n",
       " 592: 'albeit',\n",
       " 593: 'albeniz',\n",
       " 594: 'alberson',\n",
       " 595: 'albert',\n",
       " 596: 'alberta',\n",
       " 597: 'albertine',\n",
       " 598: 'albertson',\n",
       " 599: 'album',\n",
       " 600: 'albums',\n",
       " 601: 'albéniz',\n",
       " 602: 'alcantara',\n",
       " 603: 'alcohol',\n",
       " 604: 'alcoholic',\n",
       " 605: 'alcoholism',\n",
       " 606: 'alec',\n",
       " 607: 'alecia',\n",
       " 608: 'aleister',\n",
       " 609: 'alert',\n",
       " 610: 'alex',\n",
       " 611: 'alexander',\n",
       " 612: 'alexandr',\n",
       " 613: 'alexandra',\n",
       " 614: 'alexandre',\n",
       " 615: 'alfred',\n",
       " 616: 'alice',\n",
       " 617: 'alicia',\n",
       " 618: 'alien',\n",
       " 619: 'alienated',\n",
       " 620: 'alienates',\n",
       " 621: 'alienation',\n",
       " 622: 'aliens',\n",
       " 623: 'aligned',\n",
       " 624: 'alike',\n",
       " 625: 'alisha',\n",
       " 626: 'alissia',\n",
       " 627: 'alistair',\n",
       " 628: 'alive',\n",
       " 629: 'all',\n",
       " 630: 'allan',\n",
       " 631: 'allegorical',\n",
       " 632: 'allegory',\n",
       " 633: 'allen',\n",
       " 634: 'alleviate',\n",
       " 635: 'alley',\n",
       " 636: 'alliance',\n",
       " 637: 'allied',\n",
       " 638: 'allies',\n",
       " 639: 'allison',\n",
       " 640: 'allow',\n",
       " 641: 'allowed',\n",
       " 642: 'allowing',\n",
       " 643: 'allows',\n",
       " 644: 'allude',\n",
       " 645: 'allure',\n",
       " 646: 'allures',\n",
       " 647: 'alluring',\n",
       " 648: 'allusions',\n",
       " 649: 'ally',\n",
       " 650: 'almighty',\n",
       " 651: 'almodovar',\n",
       " 652: 'almora',\n",
       " 653: 'almost',\n",
       " 654: 'alock',\n",
       " 655: 'alok',\n",
       " 656: 'alone',\n",
       " 657: 'along',\n",
       " 658: 'alongside',\n",
       " 659: 'alongwith',\n",
       " 660: 'aloof',\n",
       " 661: 'alot',\n",
       " 662: 'aloy',\n",
       " 663: 'alphaville',\n",
       " 664: 'already',\n",
       " 665: 'alright',\n",
       " 666: 'also',\n",
       " 667: 'altar',\n",
       " 668: 'alte',\n",
       " 669: 'alter',\n",
       " 670: 'altercations',\n",
       " 671: 'altered',\n",
       " 672: 'altering',\n",
       " 673: 'alternate',\n",
       " 674: 'alternately',\n",
       " 675: 'alternates',\n",
       " 676: 'alternating',\n",
       " 677: 'alternative',\n",
       " 678: 'alternatively',\n",
       " 679: 'although',\n",
       " 680: 'alto',\n",
       " 681: 'altogether',\n",
       " 682: 'alun',\n",
       " 683: 'alvin',\n",
       " 684: 'always',\n",
       " 685: 'alzheimer',\n",
       " 686: 'am',\n",
       " 687: 'amadeus',\n",
       " 688: 'amagula',\n",
       " 689: 'amalgam',\n",
       " 690: 'amanda',\n",
       " 691: 'amateur',\n",
       " 692: 'amateurish',\n",
       " 693: 'amateurs',\n",
       " 694: 'amati',\n",
       " 695: 'amaze',\n",
       " 696: 'amazed',\n",
       " 697: 'amazement',\n",
       " 698: 'amazing',\n",
       " 699: 'amazingly',\n",
       " 700: 'amazon',\n",
       " 701: 'amazonas',\n",
       " 702: 'amazonians',\n",
       " 703: 'ambassador',\n",
       " 704: 'ambiance',\n",
       " 705: 'ambidexterous',\n",
       " 706: 'ambiguities',\n",
       " 707: 'ambiguity',\n",
       " 708: 'ambiguous',\n",
       " 709: 'ambition',\n",
       " 710: 'ambitions',\n",
       " 711: 'ambitious',\n",
       " 712: 'ambush',\n",
       " 713: 'ambushed',\n",
       " 714: 'amelie',\n",
       " 715: 'america',\n",
       " 716: 'american',\n",
       " 717: 'americana',\n",
       " 718: 'americanised',\n",
       " 719: 'americans',\n",
       " 720: 'ami',\n",
       " 721: 'amicable',\n",
       " 722: 'amid',\n",
       " 723: 'amidst',\n",
       " 724: 'amiss',\n",
       " 725: 'amnesic',\n",
       " 726: 'amolad',\n",
       " 727: 'among',\n",
       " 728: 'amongst',\n",
       " 729: 'amoral',\n",
       " 730: 'amorality',\n",
       " 731: 'amore',\n",
       " 732: 'amos',\n",
       " 733: 'amount',\n",
       " 734: 'amounts',\n",
       " 735: 'amoureuses',\n",
       " 736: 'amplified',\n",
       " 737: 'amply',\n",
       " 738: 'amrita',\n",
       " 739: 'amrutha',\n",
       " 740: 'amsterdam',\n",
       " 741: 'amulet',\n",
       " 742: 'amuro',\n",
       " 743: 'amuse',\n",
       " 744: 'amused',\n",
       " 745: 'amusement',\n",
       " 746: 'amusing',\n",
       " 747: 'an',\n",
       " 748: 'ana',\n",
       " 749: 'anakin',\n",
       " 750: 'anal',\n",
       " 751: 'analogy',\n",
       " 752: 'analyse',\n",
       " 753: 'analysis',\n",
       " 754: 'analyze',\n",
       " 755: 'analyzed',\n",
       " 756: 'anarchic',\n",
       " 757: 'anarchy',\n",
       " 758: 'anchor',\n",
       " 759: 'ancient',\n",
       " 760: 'ancillary',\n",
       " 761: 'and',\n",
       " 762: 'andalusia',\n",
       " 763: 'anderson',\n",
       " 764: 'andie',\n",
       " 765: 'andorra',\n",
       " 766: 'andre',\n",
       " 767: 'andrei',\n",
       " 768: 'andreu',\n",
       " 769: 'andromedia',\n",
       " 770: 'andy',\n",
       " 771: 'anecdote',\n",
       " 772: 'anesthetic',\n",
       " 773: 'angel',\n",
       " 774: 'angela',\n",
       " 775: 'angeles',\n",
       " 776: 'angeli',\n",
       " 777: 'angelic',\n",
       " 778: 'angels',\n",
       " 779: 'anger',\n",
       " 780: 'angered',\n",
       " 781: 'angle',\n",
       " 782: 'angles',\n",
       " 783: 'anglo',\n",
       " 784: 'anglophobe',\n",
       " 785: 'angry',\n",
       " 786: 'angst',\n",
       " 787: 'anguish',\n",
       " 788: 'anguished',\n",
       " 789: 'anguishing',\n",
       " 790: 'anihiliates',\n",
       " 791: 'animal',\n",
       " 792: 'animals',\n",
       " 793: 'animaniacs',\n",
       " 794: 'animated',\n",
       " 795: 'animation',\n",
       " 796: 'animatronic',\n",
       " 797: 'animatronics',\n",
       " 798: 'anime',\n",
       " 799: 'animosities',\n",
       " 800: 'anjaane',\n",
       " 801: 'anjane',\n",
       " 802: 'anjos',\n",
       " 803: 'ankle',\n",
       " 804: 'ann',\n",
       " 805: 'anna',\n",
       " 806: 'annakin',\n",
       " 807: 'annals',\n",
       " 808: 'anne',\n",
       " 809: 'annie',\n",
       " 810: 'anniversary',\n",
       " 811: 'announce',\n",
       " 812: 'announced',\n",
       " 813: 'announcement',\n",
       " 814: 'announces',\n",
       " 815: 'announcing',\n",
       " 816: 'annoyance',\n",
       " 817: 'annoyances',\n",
       " 818: 'annoyed',\n",
       " 819: 'annoying',\n",
       " 820: 'annoyingly',\n",
       " 821: 'annoys',\n",
       " 822: 'annual',\n",
       " 823: 'annually',\n",
       " 824: 'anoes',\n",
       " 825: 'anomalies',\n",
       " 826: 'another',\n",
       " 827: 'ansonia',\n",
       " 828: 'answer',\n",
       " 829: 'answered',\n",
       " 830: 'answering',\n",
       " 831: 'answers',\n",
       " 832: 'antagonist',\n",
       " 833: 'antennae',\n",
       " 834: 'antheil',\n",
       " 835: 'anthems',\n",
       " 836: 'anthology',\n",
       " 837: 'anthony',\n",
       " 838: 'anthropologist',\n",
       " 839: 'anti',\n",
       " 840: 'antichrist',\n",
       " 841: 'anticipated',\n",
       " 842: 'anticipation',\n",
       " 843: 'antics',\n",
       " 844: 'antidote',\n",
       " 845: 'antidotes',\n",
       " 846: 'antihero',\n",
       " 847: 'antipodes',\n",
       " 848: 'antiques',\n",
       " 849: 'antoine',\n",
       " 850: 'antoinette',\n",
       " 851: 'antoni',\n",
       " 852: 'antonia',\n",
       " 853: 'antonio',\n",
       " 854: 'antònia',\n",
       " 855: 'anupam',\n",
       " 856: 'anupamji',\n",
       " 857: 'anxiety',\n",
       " 858: 'anxious',\n",
       " 859: 'any',\n",
       " 860: 'anybody',\n",
       " 861: 'anyhow',\n",
       " 862: 'anymore',\n",
       " 863: 'anyone',\n",
       " 864: 'anyplace',\n",
       " 865: 'anything',\n",
       " 866: 'anytime',\n",
       " 867: 'anyway',\n",
       " 868: 'anyways',\n",
       " 869: 'anywhere',\n",
       " 870: 'ao',\n",
       " 871: 'apart',\n",
       " 872: 'apartment',\n",
       " 873: 'apartments',\n",
       " 874: 'apes',\n",
       " 875: 'apex',\n",
       " 876: 'apke',\n",
       " 877: 'aplomb',\n",
       " 878: 'apocalypse',\n",
       " 879: 'apocalyptic',\n",
       " 880: 'apologise',\n",
       " 881: 'apologize',\n",
       " 882: 'apology',\n",
       " 883: 'app',\n",
       " 884: 'appalling',\n",
       " 885: 'apparent',\n",
       " 886: 'apparently',\n",
       " 887: 'apparition',\n",
       " 888: 'apparitions',\n",
       " 889: 'appeal',\n",
       " 890: 'appealed',\n",
       " 891: 'appealing',\n",
       " 892: 'appeals',\n",
       " 893: 'appear',\n",
       " 894: 'appearance',\n",
       " 895: 'appearances',\n",
       " 896: 'appeared',\n",
       " 897: 'appearing',\n",
       " 898: 'appears',\n",
       " 899: 'appease',\n",
       " 900: 'appelation',\n",
       " 901: 'applaud',\n",
       " 902: 'applauded',\n",
       " 903: 'applauds',\n",
       " 904: 'applause',\n",
       " 905: 'apple',\n",
       " 906: 'apples',\n",
       " 907: 'applicant',\n",
       " 908: 'application',\n",
       " 909: 'applied',\n",
       " 910: 'applies',\n",
       " 911: 'apply',\n",
       " 912: 'applying',\n",
       " 913: 'appoach',\n",
       " 914: 'appointed',\n",
       " 915: 'appointment',\n",
       " 916: 'appreciable',\n",
       " 917: 'appreciate',\n",
       " 918: 'appreciated',\n",
       " 919: 'appreciates',\n",
       " 920: 'appreciating',\n",
       " 921: 'appreciation',\n",
       " 922: 'apprehension',\n",
       " 923: 'apprentice',\n",
       " 924: 'approach',\n",
       " 925: 'approached',\n",
       " 926: 'approaches',\n",
       " 927: 'approaching',\n",
       " 928: 'appropriate',\n",
       " 929: 'appropriately',\n",
       " 930: 'approval',\n",
       " 931: 'approving',\n",
       " 932: 'approximately',\n",
       " 933: 'april',\n",
       " 934: 'apt',\n",
       " 935: 'aptitude',\n",
       " 936: 'aptly',\n",
       " 937: 'arab',\n",
       " 938: 'arabic',\n",
       " 939: 'arbitrary',\n",
       " 940: 'arbuthnot',\n",
       " 941: 'arc',\n",
       " 942: 'arcadia',\n",
       " 943: 'arcane',\n",
       " 944: 'archer',\n",
       " 945: 'archers',\n",
       " 946: 'archetypical',\n",
       " 947: 'architecture',\n",
       " 948: 'archive',\n",
       " 949: 'archived',\n",
       " 950: 'archives',\n",
       " 951: 'archtypes',\n",
       " 952: 'arctic',\n",
       " 953: 'arden',\n",
       " 954: 'ardent',\n",
       " 955: 'arduous',\n",
       " 956: 'are',\n",
       " 957: 'area',\n",
       " 958: 'areas',\n",
       " 959: 'aren',\n",
       " 960: 'arena',\n",
       " 961: 'argento',\n",
       " 962: 'argh',\n",
       " 963: 'arguably',\n",
       " 964: 'argue',\n",
       " 965: 'argues',\n",
       " 966: 'arguing',\n",
       " 967: 'argument',\n",
       " 968: 'arise',\n",
       " 969: 'aristocrat',\n",
       " 970: 'aristotelian',\n",
       " 971: 'arizona',\n",
       " 972: 'ark',\n",
       " 973: 'arkansas',\n",
       " 974: 'arkush',\n",
       " 975: 'arlington',\n",
       " 976: 'arm',\n",
       " 977: 'armani',\n",
       " 978: 'armchair',\n",
       " 979: 'armed',\n",
       " 980: 'armena',\n",
       " 981: 'armies',\n",
       " 982: 'arming',\n",
       " 983: 'armor',\n",
       " 984: 'armour',\n",
       " 985: 'armoury',\n",
       " 986: 'arms',\n",
       " 987: 'armstrong',\n",
       " 988: 'army',\n",
       " 989: 'arnaz',\n",
       " 990: 'arness',\n",
       " 991: 'arngrim',\n",
       " 992: 'arnim',\n",
       " 993: 'arnold',\n",
       " 994: 'around',\n",
       " 995: 'arouses',\n",
       " 996: 'arrange',\n",
       " 997: 'arranged',\n",
       " 998: 'arrangement',\n",
       " 999: 'arranging',\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb50e0",
   "metadata": {},
   "source": [
    "Padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d620ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus['tokens'] = tokenized_corpus['tokens'].apply(lambda x: [PAD_TOKEN] * CONTEXT_SIZE + x + [PAD_TOKEN] * CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2caf88602aabaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['<PAD>', '<PAD>', 'high', 'is'] -> Target: bromwell\n",
      "Context: ['<PAD>', 'bromwell', 'is', 'a'] -> Target: high\n",
      "Context: ['bromwell', 'high', 'a', 'cartoon'] -> Target: is\n",
      "Context: ['high', 'is', 'cartoon', 'comedy'] -> Target: a\n",
      "Context: ['is', 'a', 'comedy', 'it'] -> Target: cartoon\n"
     ]
    }
   ],
   "source": [
    "# Create CBOW dataset from padded sentences\n",
    "cbow_data = []\n",
    "for tokens in tokenized_corpus['tokens']:\n",
    "    for i in range(CONTEXT_SIZE, len(tokens) - CONTEXT_SIZE):\n",
    "        context = tokens[i - CONTEXT_SIZE:i] + tokens[i + 1:i + CONTEXT_SIZE + 1]\n",
    "        target = tokens[i]\n",
    "        cbow_data.append((context, target))\n",
    "\n",
    "# Show a few examples\n",
    "for context, target in cbow_data[:5]:\n",
    "    print(f\"Context: {context} -> Target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7080552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, data, word_to_idx):\n",
    "        self.data = data\n",
    "        self.word_to_idx = word_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        context_idxs = torch.tensor([self.word_to_idx[w] for w in context], dtype=torch.long)\n",
    "        target_idx = torch.tensor(self.word_to_idx[target], dtype=torch.long)\n",
    "        return context_idxs, target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29b29ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOWDataset size: 193551\n",
      "Context indices: tensor([10603, 14278, 14030,  1406])\n",
      "Target index: 2190\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the CBOW dataset object for model training\n",
    "# Split cbow_data into train and validation sets\n",
    "\n",
    "cbow_train_data, cbow_val_data = train_test_split(cbow_data, test_size=0.2, random_state=42)\n",
    "\n",
    "cbow_train_dataset = CBOWDataset(cbow_train_data, word_to_idx)\n",
    "cbow_val_dataset = CBOWDataset(cbow_val_data, word_to_idx)\n",
    "\n",
    "# Use train dataset for the rest of this cell\n",
    "cbow_dataset = cbow_train_dataset\n",
    "print(f\"CBOWDataset size: {len(cbow_dataset)}\")\n",
    "# Example: get the first item (context indices, target index)\n",
    "context_idxs, target_idx = cbow_dataset[0]\n",
    "print(f\"Context indices: {context_idxs}\")\n",
    "print(f\"Target index: {target_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c1b87710020fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word_to_idx[PAD_TOKEN])\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_idxs):\n",
    "        # context_idxs: (batch_size, 2*CONTEXT_SIZE)\n",
    "        embeds = self.embeddings(context_idxs)  # (batch_size, 2*CONTEXT_SIZE, embedding_dim)\n",
    "        avg_embeds = embeds.mean(dim=1)        # (batch_size, embedding_dim)\n",
    "        out = self.linear(avg_embeds)          # (batch_size, vocab_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba786e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader for the CBOW dataset\n",
    "cbow_train_dataloader = DataLoader(\n",
    "    cbow_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "cbow_val_dataloader = DataLoader(\n",
    "    cbow_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1323b4691c8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 7.5036\n",
      "Validation Accuracy: 0.0700, F1 Score: 0.0184\n",
      "Validation Accuracy: 0.0700, F1 Score: 0.0184\n",
      "Epoch [2/20], Loss: 6.6807\n",
      "Epoch [2/20], Loss: 6.6807\n",
      "Validation Accuracy: 0.0788, F1 Score: 0.0253\n",
      "Validation Accuracy: 0.0788, F1 Score: 0.0253\n",
      "Epoch [3/20], Loss: 6.4803\n",
      "Epoch [3/20], Loss: 6.4803\n",
      "Validation Accuracy: 0.0838, F1 Score: 0.0300\n",
      "Validation Accuracy: 0.0838, F1 Score: 0.0300\n",
      "Epoch [4/20], Loss: 6.3613\n",
      "Epoch [4/20], Loss: 6.3613\n",
      "Validation Accuracy: 0.0895, F1 Score: 0.0350\n",
      "Validation Accuracy: 0.0895, F1 Score: 0.0350\n",
      "Epoch [5/20], Loss: 6.2764\n",
      "Epoch [5/20], Loss: 6.2764\n",
      "Validation Accuracy: 0.0933, F1 Score: 0.0378\n",
      "Validation Accuracy: 0.0933, F1 Score: 0.0378\n",
      "Epoch [6/20], Loss: 6.2108\n",
      "Epoch [6/20], Loss: 6.2108\n",
      "Validation Accuracy: 0.0976, F1 Score: 0.0405\n",
      "Validation Accuracy: 0.0976, F1 Score: 0.0405\n",
      "Epoch [7/20], Loss: 6.1574\n",
      "Epoch [7/20], Loss: 6.1574\n",
      "Validation Accuracy: 0.1003, F1 Score: 0.0429\n",
      "Validation Accuracy: 0.1003, F1 Score: 0.0429\n",
      "Epoch [8/20], Loss: 6.1126\n",
      "Epoch [8/20], Loss: 6.1126\n",
      "Validation Accuracy: 0.1037, F1 Score: 0.0455\n",
      "Validation Accuracy: 0.1037, F1 Score: 0.0455\n",
      "Epoch [9/20], Loss: 6.0734\n",
      "Epoch [9/20], Loss: 6.0734\n",
      "Validation Accuracy: 0.1055, F1 Score: 0.0468\n",
      "Validation Accuracy: 0.1055, F1 Score: 0.0468\n",
      "Epoch [10/20], Loss: 6.0394\n",
      "Epoch [10/20], Loss: 6.0394\n",
      "Validation Accuracy: 0.1070, F1 Score: 0.0488\n",
      "Validation Accuracy: 0.1070, F1 Score: 0.0488\n",
      "Epoch [11/20], Loss: 6.0086\n",
      "Epoch [11/20], Loss: 6.0086\n",
      "Validation Accuracy: 0.1087, F1 Score: 0.0503\n",
      "Validation Accuracy: 0.1087, F1 Score: 0.0503\n",
      "Epoch [12/20], Loss: 5.9807\n",
      "Epoch [12/20], Loss: 5.9807\n",
      "Validation Accuracy: 0.1098, F1 Score: 0.0511\n",
      "Validation Accuracy: 0.1098, F1 Score: 0.0511\n",
      "Epoch [13/20], Loss: 5.9553\n",
      "Epoch [13/20], Loss: 5.9553\n",
      "Validation Accuracy: 0.1103, F1 Score: 0.0526\n",
      "Validation Accuracy: 0.1103, F1 Score: 0.0526\n",
      "Epoch [14/20], Loss: 5.9318\n",
      "Epoch [14/20], Loss: 5.9318\n",
      "Validation Accuracy: 0.1121, F1 Score: 0.0535\n",
      "Validation Accuracy: 0.1121, F1 Score: 0.0535\n",
      "Epoch [15/20], Loss: 5.9103\n",
      "Epoch [15/20], Loss: 5.9103\n",
      "Validation Accuracy: 0.1139, F1 Score: 0.0544\n",
      "Validation Accuracy: 0.1139, F1 Score: 0.0544\n",
      "Epoch [16/20], Loss: 5.8906\n",
      "Epoch [16/20], Loss: 5.8906\n",
      "Validation Accuracy: 0.1125, F1 Score: 0.0547\n",
      "Validation Accuracy: 0.1125, F1 Score: 0.0547\n",
      "Epoch [17/20], Loss: 5.8716\n",
      "Epoch [17/20], Loss: 5.8716\n",
      "Validation Accuracy: 0.1136, F1 Score: 0.0557\n",
      "Validation Accuracy: 0.1136, F1 Score: 0.0557\n",
      "Epoch [18/20], Loss: 5.8544\n",
      "Epoch [18/20], Loss: 5.8544\n",
      "Validation Accuracy: 0.1143, F1 Score: 0.0556\n",
      "Validation Accuracy: 0.1143, F1 Score: 0.0556\n",
      "Epoch [19/20], Loss: 5.8382\n",
      "Epoch [19/20], Loss: 5.8382\n",
      "Validation Accuracy: 0.1141, F1 Score: 0.0562\n",
      "Validation Accuracy: 0.1141, F1 Score: 0.0562\n",
      "Epoch [20/20], Loss: 5.8227\n",
      "Epoch [20/20], Loss: 5.8227\n",
      "Validation Accuracy: 0.1154, F1 Score: 0.0570\n",
      "Validation Accuracy: 0.1154, F1 Score: 0.0570\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Create DataLoaders for train and validation datasets\n",
    "model = CBOW(vocab_size, EMBEDDING_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_context_idxs, batch_target_idxs in cbow_train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_context_idxs)\n",
    "        loss = criterion(outputs, batch_target_idxs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(cbow_train_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_context_idxs, batch_target_idxs in cbow_val_dataloader:\n",
    "            outputs = model(batch_context_idxs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(batch_target_idxs.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c25d8ff938e2801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['i', 'didn', 'know', 'this']\n",
      "Top predictions for center word:\n",
      "  t: 0.8064\n",
      "  movie: 0.0126\n",
      "  was: 0.0079\n",
      "  say: 0.0069\n",
      "  would: 0.0062\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cbow(model, context_words):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        context_idxs = torch.tensor([word_to_idx[w] for w in context_words], dtype=torch.long).unsqueeze(0)\n",
    "        output = model(context_idxs)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        top_prob, top_idx = torch.topk(probs, 5)  # top 5 predictions\n",
    "\n",
    "        print(f\"Context: {context_words}\")\n",
    "        print(\"Top predictions for center word:\")\n",
    "        for prob, idx in zip(top_prob[0], top_idx[0]):\n",
    "            print(f\"  {idx_to_word[idx.item()]}: {prob.item():.4f}\")\n",
    "\n",
    "# Example: I didn't know this -> [i], [didn], [t], [know], [this]\n",
    "context_example = ['i', 'didn', 'know', 'this']\n",
    "evaluate_cbow(model, context_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d22c8e4bd8c72",
   "metadata": {},
   "source": [
    "## Task 2: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f336562a89e0b9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Skip-Gram Pairs:\n",
      "Center: 'bromwell' -> Target Context: '<PAD>'\n",
      "Center: 'bromwell' -> Target Context: '<PAD>'\n",
      "Center: 'bromwell' -> Target Context: 'high'\n",
      "Center: 'bromwell' -> Target Context: 'is'\n",
      "Center: 'high' -> Target Context: '<PAD>'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare training data for SkipGram, i.e. (center_word, context_words), e.g., ('is', ['bromwell', 'high', 'a', 'cartoon'])\n",
    "\n",
    "# Re-generate skipgram_data for (center_word, target_context_word) pairs\n",
    "skipgram_data_pairs = []\n",
    "\n",
    "\n",
    "for context_words_list, center_word_for_cbow in cbow_data:\n",
    "    # For Skip-Gram, center_word_for_cbow is the 'input' word\n",
    "    # Each word in context_words_list is a 'target' context word\n",
    "    for target_context_word in context_words_list:\n",
    "        skipgram_data_pairs.append((center_word_for_cbow, target_context_word))\n",
    "        \n",
    "print(\"Generated Skip-Gram Pairs:\")\n",
    "for center, context_target in skipgram_data_pairs[:5]:\n",
    "    print(f\"Center: '{center}' -> Target Context: '{context_target}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6c22d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, data_pairs, word_to_idx):\n",
    "        # data_pairs is now a list of (center_word_str, target_context_word_str) tuples\n",
    "        self.data = data_pairs\n",
    "        self.word_to_idx = word_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        center_word_str, target_context_word_str = self.data[idx]\n",
    "        center_idx = torch.tensor(self.word_to_idx[center_word_str], dtype=torch.long)\n",
    "        target_context_idx = torch.tensor(self.word_to_idx[target_context_word_str], dtype=torch.long)\n",
    "        return center_idx, target_context_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3768bb5eaf7750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word_to_idx[PAD_TOKEN])\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, center_word_idx):\n",
    "        center_embedding = self.embeddings(center_word_idx)\n",
    "        context_scores = self.linear(center_embedding)\n",
    "        return context_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ae8c8bbe08e906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipGram(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "\n",
    "skipgram_train_data, skipgram_val_data = train_test_split(skipgram_data_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "skipgram_train_dataset = SkipGramDataset(skipgram_train_data, word_to_idx)\n",
    "skipgram_val_dataset = SkipGramDataset(skipgram_val_data, word_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41b3844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_train_dataloader = DataLoader(\n",
    "    skipgram_train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "skipgram_val_dataloader = DataLoader(\n",
    "    skipgram_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62882207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 7.1574\n",
      "Validation Accuracy: 0.0646, F1 Score: 0.0173\n",
      "Epoch [2/20], Loss: 6.7971\n",
      "Validation Accuracy: 0.0657, F1 Score: 0.0189\n",
      "Epoch [3/20], Loss: 6.7691\n",
      "Validation Accuracy: 0.0672, F1 Score: 0.0213\n",
      "Epoch [4/20], Loss: 6.7521\n",
      "Validation Accuracy: 0.0685, F1 Score: 0.0236\n",
      "Epoch [5/20], Loss: 6.7399\n",
      "Validation Accuracy: 0.0693, F1 Score: 0.0244\n",
      "Epoch [6/20], Loss: 6.7300\n",
      "Validation Accuracy: 0.0690, F1 Score: 0.0239\n",
      "Epoch [7/20], Loss: 6.7183\n",
      "Validation Accuracy: 0.0705, F1 Score: 0.0261\n",
      "Epoch [8/20], Loss: 6.7056\n",
      "Validation Accuracy: 0.0705, F1 Score: 0.0256\n",
      "Epoch [9/20], Loss: 6.6949\n",
      "Validation Accuracy: 0.0705, F1 Score: 0.0257\n",
      "Epoch [10/20], Loss: 6.6850\n",
      "Validation Accuracy: 0.0716, F1 Score: 0.0269\n",
      "Epoch [11/20], Loss: 6.6777\n",
      "Validation Accuracy: 0.0717, F1 Score: 0.0270\n",
      "Epoch [12/20], Loss: 6.6707\n",
      "Validation Accuracy: 0.0719, F1 Score: 0.0268\n",
      "Epoch [13/20], Loss: 6.6644\n",
      "Validation Accuracy: 0.0717, F1 Score: 0.0271\n",
      "Epoch [14/20], Loss: 6.6589\n",
      "Validation Accuracy: 0.0715, F1 Score: 0.0276\n",
      "Epoch [15/20], Loss: 6.6541\n",
      "Validation Accuracy: 0.0716, F1 Score: 0.0274\n",
      "Epoch [16/20], Loss: 6.6490\n",
      "Validation Accuracy: 0.0717, F1 Score: 0.0275\n",
      "Epoch [17/20], Loss: 6.6460\n",
      "Validation Accuracy: 0.0713, F1 Score: 0.0269\n",
      "Epoch [18/20], Loss: 6.6425\n",
      "Validation Accuracy: 0.0710, F1 Score: 0.0267\n",
      "Epoch [19/20], Loss: 6.6394\n",
      "Validation Accuracy: 0.0712, F1 Score: 0.0268\n",
      "Epoch [20/20], Loss: 6.6358\n",
      "Validation Accuracy: 0.0713, F1 Score: 0.0274\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # batch_center_idxs: (batch_size,)\n",
    "    # batch_target_context_idxs: (batch_size,) - no longer a list of contexts\n",
    "    for batch_center_idxs, batch_target_context_idxs in skipgram_train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_center_idxs) # outputs shape: (batch_size, vocab_size)\n",
    "\n",
    "        # The target for CrossEntropyLoss should be a 1D tensor of class indices (the target words)\n",
    "        # Its batch dimension must match the input (outputs)\n",
    "        loss = criterion(outputs, batch_target_context_idxs) # Corrected! No .view(-1) needed.\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(skipgram_train_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_center_idxs, batch_target_context_idxs in skipgram_val_dataloader:\n",
    "            outputs = model(batch_center_idxs)\n",
    "            _, preds = torch.max(outputs, 1) # preds will be (batch_size,)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            # batch_target_context_idxs is already 1D\n",
    "            all_targets.extend(batch_target_context_idxs.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12a2de3d23bd45fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center word: 'can'\n",
      "Top predictions for context words:\n",
      "  you: 0.0532\n",
      "  i: 0.0402\n",
      "  t: 0.0385\n",
      "  it: 0.0326\n",
      "  to: 0.0320\n"
     ]
    }
   ],
   "source": [
    "def evaluate_skipgram(model, center_word):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_idx = torch.tensor([word_to_idx[center_word]], dtype=torch.long)  # (1,)\n",
    "        output = model(input_idx)  # (1, vocab_size)\n",
    "        \n",
    "        # For each context position, get top predictions\n",
    "        context_preds = output.squeeze(0)  # (vocab_size,)\n",
    "        probs = torch.softmax(context_preds, dim=0)\n",
    "        top_prob, top_idx = torch.topk(probs, 5)  # top\n",
    "        \n",
    "        print(f\"Center word: '{center_word}'\")\n",
    "        print(\"Top predictions for context words:\")\n",
    "        for prob, idx in zip(top_prob, top_idx):\n",
    "            print(f\"  {idx_to_word[idx.item()]}: {prob.item():.4f}\")\n",
    "\n",
    "# Example usage\n",
    "center_word_example = 'can'\n",
    "evaluate_skipgram(model, center_word_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64c60906e47f34",
   "metadata": {},
   "source": [
    "## Task 3: Cosine Similarity\n",
    "Make sure that you have installed the package gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5469eec5181af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge gensim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dae65ed8b9b4145",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[32m     16\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIndexedCorpus\u001b[39;00m(interfaces.CorpusABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCorpusABC\u001b[39;00m(utils.SaveLoad):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[39m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.\u001b[39m - \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 & set2)) / \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlogsumexp\u001b[39m(x):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Passau/dlnlp/.venv/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[39m, in \u001b[36minit gensim._matutils\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04ce26e1618203",
   "metadata": {},
   "source": [
    "### Task 3 (a): Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0c2f644d52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return dot(x, y) / (norm(x) * norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341dd143b9fb14c8",
   "metadata": {},
   "source": [
    "### Task 3 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b85a015e73c0e2",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d61bef439acf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KeyedVectors.load_word2vec_format(datapath('word2vec_pre_kv_c'), binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbb0bb5095b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector_m1 = model1.get_vector('king')\n",
    "queen_vector_m1 = model1.get_vector('queen')\n",
    "man_vector_m1 = model1.get_vector('man')\n",
    "woman_vector_m1 = model1.get_vector('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc59d8b29bfa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51200b3115175a",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863230ee617a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KeyedVectors.load_word2vec_format(datapath('high_precision.kv.bin'), binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc6ebd53904af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector_m2 = model2.get_vector('king')\n",
    "queen_vector_m2 = model2.get_vector('queen')\n",
    "man_vector_m2 = model2.get_vector('man')\n",
    "woman_vector_m2 = model2.get_vector('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983221de39ed40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba4315621799da1",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f5f1f1e6255ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = KeyedVectors.load_word2vec_format(datapath('euclidean_vectors.bin'), binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8b1800eb7dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector_m3 = model3.get_vector('king')\n",
    "queen_vector_m3 = model3.get_vector('queen')\n",
    "man_vector_m3 = model3.get_vector('man')\n",
    "woman_vector_m3 = model3.get_vector('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e71062b11389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680d6a91045774d",
   "metadata": {},
   "source": [
    "#### Analogy Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe22173b6167b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_mins_man_plus_woman_m3 = (king_vector_m3 - man_vector_m3) + woman_vector_m3\n",
    "\n",
    "# Make sure you have implemented cosine similarity. \n",
    "cosine_similarity(king_mins_man_plus_woman_m3, queen_vector_m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b2f0b3af40ebe",
   "metadata": {},
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae4a24504312ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_google = gensim.downloader.load('word2vec-google-news-300');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e32e7da1a6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2vec_google.get_vector('king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805490c424e7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also try the GLOVE model\n",
    "glove_google = gensim.downloader.load('glove-wiki-gigaword-100');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb443a866e9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glove_google.get_vector('king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7464acc6b77a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = word2vec_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba910248b1d4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector_m4 = model4.get_vector('king')\n",
    "queen_vector_m4 = model4.get_vector('queen')\n",
    "man_vector_m4 = model4.get_vector('man')\n",
    "woman_vector_m4 = model4.get_vector('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652677473d83b816",
   "metadata": {},
   "source": [
    "#### Analogy Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d43cd93f0c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_mins_man_plus_woman_m4 = (king_vector_m4 - man_vector_m4) + woman_vector_m4\n",
    "\n",
    "# Make sure you have implemented cosine similarity. \n",
    "cosine_similarity(king_mins_man_plus_woman_m4, queen_vector_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459734e0cacc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a method to search for similar words given a word\n",
    "# Hint: you can use a method of the word2vec_google object\n",
    "\n",
    "similar_words = model4.most_similar('phone', topn=10)\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0835f5923afa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = model4.most_similar('king', topn=10)\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef941245b07d523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to find at least five analogies using the method you found above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a03c120788ab27",
   "metadata": {},
   "source": [
    "## Theoretical Question #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e1ef4589d3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_google.IDENTIFIED_METHOD(king_mins_man_plus_woman_m4) # First answer will be King"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
